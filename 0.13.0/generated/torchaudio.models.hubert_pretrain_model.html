


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchaudio.models.hubert_pretrain_model &mdash; Torchaudio nightly documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="torchaudio.models.hubert_pretrain_base" href="torchaudio.models.hubert_pretrain_base.html" />
    <link rel="prev" title="torchaudio.models.hubert_xlarge" href="torchaudio.models.hubert_xlarge.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://shiftlab.github.io/pytorch/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://shiftlab.github.io/pytorch/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/features">Features</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   
  <div>

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href="../../versions.html">Nightly Build (0.13.0+0f1d13b) &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Torchaudio Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Index</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_features.html">Supported Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html">References</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../torchaudio.html">torchaudio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../io.html">torchaudio.io</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend.html">torchaudio.backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional.html">torchaudio.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../transforms.html">torchaudio.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets.html">torchaudio.datasets</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../models.html">torchaudio.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models.decoder.html">torchaudio.models.decoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pipelines.html">torchaudio.pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sox_effects.html">torchaudio.sox_effects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../compliance.kaldi.html">torchaudio.compliance.kaldi</a></li>
<li class="toctree-l1"><a class="reference internal" href="../kaldi_io.html">torchaudio.kaldi_io</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils.html">torchaudio.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Prototype API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../prototype.html">torchaudio.prototype</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prototype.functional.html">torchaudio.prototype.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prototype.models.html">torchaudio.prototype.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prototype.pipelines.html">torchaudio.prototype.pipelines</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.io.html">Media IO</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/audio_resampling_tutorial.html">Audio Resampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/audio_data_augmentation_tutorial.html">Audio Data Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/audio_feature_extractions_tutorial.html">Audio Feature Extractions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/audio_feature_augmentation_tutorial.html">Audio Feature Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/audio_datasets_tutorial.html">Audio Datasets</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Usages</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/speech_recognition_pipeline_tutorial.html">Speech Recognition with Wav2Vec2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/online_asr_tutorial.html">Online ASR with Emformer RNN-T</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/device_asr.html">Device ASR with Emformer RNN-T</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/forced_alignment_tutorial.html">Forced Alignment with Wav2Vec2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/tacotron2_pipeline_tutorial.html">Text-to-Speech with Tacotron2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/mvdr_tutorial.html">Speech Enhancement with MVDR Beamforming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/asr_inference_with_ctc_decoder_tutorial.html">ASR Inference with CTC Decoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/hybrid_demucs_tutorial.html">Music Source Separation with Hybrid Demucs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PyTorch Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/docs">PyTorch</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/elastic/">TorchElastic</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="http://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">

      <section data-toggle="wy-nav-shift" class="pytorch-content-wrap">
        <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
          <div class="pytorch-breadcrumbs-wrapper">
            















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../models.html">torchaudio.models</a> &gt;</li>
        
      <li>torchaudio.models.hubert_pretrain_model</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/generated/torchaudio.models.hubert_pretrain_model.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
          </div>

          <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
            Shortcuts
          </div>
        </div>

        <div class="pytorch-content-left">
    
    
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" class="pytorch-article">
              
  <div class="section" id="torchaudio-models-hubert-pretrain-model">
<h1>torchaudio.models.hubert_pretrain_model<a class="headerlink" href="#torchaudio-models-hubert-pretrain-model" title="Permalink to this heading">¶</a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="torchaudio.models.hubert_pretrain_model">
<span class="sig-prename descclassname"><span class="pre">torchaudio.models.</span></span><span class="sig-name descname"><span class="pre">hubert_pretrain_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">extractor_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.10)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">extractor_conv_layer_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.10)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.10)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.10)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">extractor_conv_bias</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_embed_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_projection_dropout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_pos_conv_kernel</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_pos_conv_groups</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_num_layers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_num_heads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_attention_dropout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_ff_interm_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_ff_interm_dropout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_dropout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_layer_norm_first</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_layer_drop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_prob</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_selection</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.10)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_other</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">no_mask_overlap</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_min_space</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_channel_prob</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_channel_selection</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.10)"><span class="pre">str</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_channel_other</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_channel_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">no_mask_channel_overlap</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_channel_min_space</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_masked</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_nomask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><span class="pre">bool</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">final_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_grad_mult</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.10)"><span class="pre">Optional</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="torchaudio.models.HuBERTPretrainModel.html#torchaudio.models.HuBERTPretrainModel" title="torchaudio.models.wav2vec2.model.HuBERTPretrainModel"><span class="pre">HuBERTPretrainModel</span></a></span></span><a class="reference internal" href="../_modules/torchaudio/models/wav2vec2/model.html#hubert_pretrain_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torchaudio.models.hubert_pretrain_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds custom <a class="reference internal" href="torchaudio.models.HuBERTPretrainModel.html#torchaudio.models.HuBERTPretrainModel" title="torchaudio.models.HuBERTPretrainModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">HuBERTPretrainModel</span></code></a> for training from scratch</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The “feature extractor” below corresponds to
<a class="reference external" href="https://github.com/pytorch/fairseq/blob/dd3bd3c0497ae9a7ae7364404a6b0a4c501780b3/fairseq/models/wav2vec/wav2vec2.py#L736">ConvFeatureExtractionModel</a>
in the original <code class="docutils literal notranslate"><span class="pre">fairseq</span></code> implementation.
This is referred as “(convolutional) feature encoder” in the <em>wav2vec 2.0</em>
<span id="id1">[<a class="reference internal" href="../references.html#id14" title="Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, and Michael Auli. Wav2vec 2.0: a framework for self-supervised learning of speech representations. 2020. arXiv:2006.11477.">Baevski <em>et al.</em>, 2020</a>]</span> paper.</p>
<p>The “encoder” below corresponds to <a class="reference external" href="https://github.com/pytorch/fairseq/blob/dd3bd3c0497ae9a7ae7364404a6b0a4c501780b3/fairseq/models/wav2vec/wav2vec2.py#L817">TransformerEncoder</a>,
and this is referred as “Transformer” in the paper.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>extractor_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.10)"><em>str</em></a>) – <p>Operation mode of feature extractor.
Valid values are <code class="docutils literal notranslate"><span class="pre">&quot;group_norm&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;layer_norm&quot;</span></code>.
If <code class="docutils literal notranslate"><span class="pre">&quot;group_norm&quot;</span></code>, then a single normalization is applied
in the first convolution block. Otherwise, all the convolution
blocks will have layer normalization.</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">extractor_mode</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>extractor_conv_layer_config</strong> (<em>list of python:integer tuples</em><em> or </em><em>None</em>) – <p>Configuration of convolution layers in feature extractor.
List of convolution configuration,
i.e. <code class="docutils literal notranslate"><span class="pre">[(output_channel,</span> <span class="pre">kernel_size,</span> <span class="pre">stride),</span> <span class="pre">...]</span></code></p>
<p>If <code class="docutils literal notranslate"><span class="pre">None</span></code> is provided, then the following default value is used.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[</span>
  <span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<span class="p">]</span>
</pre></div>
</div>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">conv_feature_layers</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>extractor_conv_bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><em>bool</em></a>) – <p>Whether to include bias term to each convolution operation.</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">conv_bias</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>encoder_embed_dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – <p>The dimension of embedding in encoder.</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">encoder_embed_dim</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>encoder_projection_dropout</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a>) – <p>The dropout probability applied after the input feature is projected
to <code class="docutils literal notranslate"><span class="pre">encoder_embed_dim</span></code>.</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">dropout_input</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>encoder_pos_conv_kernel</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – <p>The kernel size of convolutional positional embeddings.</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">conv_pos</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>encoder_pos_conv_groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – <p>The number of groups of convolutional positional embeddings.</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">conv_pos_groups</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>encoder_num_layers</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – <p>The number of self attention layers in transformer block.</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">encoder_layers</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>encoder_num_heads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – <p>The number of heads in self attention layers.</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">encoder_attention_heads</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>encoder_attention_dropout</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a>) – <p>The dropout probability applied after softmax in self-attention layer.</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">attention_dropout</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>encoder_ff_interm_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – <p>The dimension of hidden features in feed forward layer.</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">encoder_ffn_embed_dim</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>encoder_ff_interm_dropout</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a>) – <p>The dropout probability applied in feedforward layer.</p>
<p>This option correspinds to <code class="docutils literal notranslate"><span class="pre">activation_dropout</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>encoder_dropout</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a>) – <p>The dropout probability applied at the end of feed forward layer.</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">dropout</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>encoder_layer_norm_first</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><em>bool</em></a>) – <p>Control the order of layer norm in transformer layer and each encoder layer.
If True, in transformer layer, layer norm is applied before features are fed
to encoder layers. In encoder layer, two layer norms are applied before and after
self attention.
If False, in transformer layer, layer norm is applied after features are fed
to encoder layers. In encoder layer, two layer norms are applied after self
attention, before and after feed forward.</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">layer_norm_first</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>encoder_layer_drop</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a>) – <p>Probability to drop each encoder layer during training.</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">layerdrop</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>mask_prob</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a>) – <p>Probability for each token to be chosen as start of the span to be masked. this will be multiplied by
number of timesteps divided by length of mask span to mask approximately this percentage of all elements.
However due to overlaps, the actual number will be smaller (unless no_overlap is True).</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">mask_prob</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>mask_selection</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.10)"><em>str</em></a>) – <p>How to choose the mask length. Options: [<code class="docutils literal notranslate"><span class="pre">static</span></code>, <code class="docutils literal notranslate"><span class="pre">uniform</span></code>, <code class="docutils literal notranslate"><span class="pre">normal</span></code>, <code class="docutils literal notranslate"><span class="pre">poisson</span></code>].</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">mask_selection</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>mask_other</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a>) – <p>Secondary mask argument (used for more complex distributions).</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">mask_other</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>mask_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – <p>The lengths of the mask.</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">mask_length</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>no_mask_overlap</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><em>bool</em></a>) – <p>Whether to allow masks to overlap.</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">no_mask_overlap</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>mask_min_space</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – <p>Minimum space between spans (if no overlap is enabled).</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">mask_min_space</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>mask_channel_prob</strong> – <p>(float):
The probability of replacing a feature with 0.</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">mask_channel_prob</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>mask_channel_selection</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.10)"><em>str</em></a>) – <p>How to choose the mask length for channel masking. Options: [<code class="docutils literal notranslate"><span class="pre">static</span></code>, <code class="docutils literal notranslate"><span class="pre">uniform</span></code>, <code class="docutils literal notranslate"><span class="pre">normal</span></code>, <code class="docutils literal notranslate"><span class="pre">poisson</span></code>].</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">mask_channel_selection</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>mask_channel_other</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a>) – <p>Secondary mask argument for channel masking(used for more complex distributions).</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">mask_channel_other</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>mask_channel_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – <p>Minimum space between spans (if no overlap is enabled) for channel masking.</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">mask_channel_length</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>no_mask_channel_overlap</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><em>bool</em></a>) – <p>Whether to allow channel masks to overlap.</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">no_mask_channel_overlap</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>mask_channel_min_space</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – <p>Minimum space between spans for channel masking(if no overlap is enabled).</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">mask_channel_min_space</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>skip_masked</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><em>bool</em></a>) – <p>If True, skip computing losses over masked frames.</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">skip_masked</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>skip_nomask</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.10)"><em>bool</em></a>) – <p>If True, skip computing losses over unmasked frames.</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">skip_nomask</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>num_classes</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – The number of classes in the labels.</p></li>
<li><p><strong>final_dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)"><em>int</em></a>) – <p>Project final representations and targets to <cite>final_dim</cite>.</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">final_dim</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
<li><p><strong>feature_grad_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.10)"><em>float</em></a><em> or </em><em>None</em>) – <p>The factor to scale the convolutional feature extraction layer gradients by.
The scale factor will not affect the forward pass.</p>
<p>This option corresponds to <code class="docutils literal notranslate"><span class="pre">feature_grad_mult</span></code> from <code class="docutils literal notranslate"><span class="pre">fairseq</span></code>.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The resulting model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="torchaudio.models.HuBERTPretrainModel.html#torchaudio.models.HuBERTPretrainModel" title="torchaudio.models.HuBERTPretrainModel">HuBERTPretrainModel</a></p>
</dd>
</dl>
</dd></dl>

</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="torchaudio.models.hubert_pretrain_base.html" class="btn btn-neutral float-right" title="torchaudio.models.hubert_pretrain_base" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="torchaudio.models.hubert_xlarge.html" class="btn btn-neutral" title="torchaudio.models.hubert_xlarge" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Torchaudio Contributors.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

          </div>


        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">torchaudio.models.hubert_pretrain_model</a></li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>
  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'nightly',
            LANGUAGE:'en',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.js"></script>
      <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/contrib/auto-render.min.js"></script>
      <script type="text/javascript" src="../_static/katex_autorenderer.js"></script>

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <script type="text/javascript">
    var collapsedSections = []
    </script>
     
    <script type="text/javascript">
      $(document).ready(function() {
	  var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
	  if (downloadNote.length >= 1) {
	      var tutorialUrl = $("#tutorial-type").text();
	      var githubLink = "https://github.com/pytorch/audio/blob/main/examples/"  + tutorialUrl + ".py",
		  notebookLink = $(".reference.download")[1].href,
		  notebookDownloadPath = notebookLink.split('_downloads')[1],
		  colabLink = "https://colab.research.google.com/github/pytorch/audio/blob/gh-pages/main/_downloads" + notebookDownloadPath;

	      $(".pytorch-call-to-action-links a[data-response='Run in Google Colab']").attr("href", colabLink);
	      $(".pytorch-call-to-action-links a[data-response='View on Github']").attr("href", githubLink);
	  }

          var overwrite = function(_) {
              if ($(this).length > 0) {
                  $(this)[0].href = "https://github.com/pytorch/audio"
              }
          }
          // PC
          $(".main-menu a:contains('GitHub')").each(overwrite);
          // Mobile
          $(".main-menu a:contains('Github')").each(overwrite);
      });

      
    </script>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://shiftlab.github.io/pytorch/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://shiftlab.github.io/pytorch/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://shiftlab.github.io/pytorch/">PyTorch</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/get-started">Get Started</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/features">Features</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/ecosystem">Ecosystem</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/blog/">Blog</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/resources">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://shiftlab.github.io/pytorch/support">Support</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.slack.com" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://shiftlab.github.io/pytorch/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    mobileMenu.bind();
    mobileTOC.bind();
    pytorchAnchors.bind();

    $(window).on("load", function() {
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
    })

    // Add class to links that have code blocks, since we cannot create links in code blocks
    $("article.pytorch-article a span.pre").each(function(e) {
      $(this).closest("a").addClass("has-code");
    });
  </script>
</body>
</html>