


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchaudio.io._stream_writer &mdash; Torchaudio 2.1.1 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href="../../../../versions.html"><span style="font-size:110%">2.1.1 &#x25BC</span></a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Torchaudio Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../index.html">Index</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../supported_features.html">Supported Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../feature_classifications.html">Feature Classifications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logo.html">TorchAudio Logo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../references.html">References</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../installation.html">Installing pre-built binaries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../build.html">Building from source</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../build.linux.html">Building on Linux and macOS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../build.windows.html">Building on Windows</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../build.jetson.html">Building on Jetson</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../build.ffmpeg.html">Enabling GPU video decoder/encoder</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/audio_io_tutorial.html">Audio I/O</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/streamreader_basic_tutorial.html">StreamReader Basic Usages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/streamreader_advanced_tutorial.html">StreamReader Advanced Usages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/streamwriter_basic_tutorial.html">StreamWriter Basic Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/streamwriter_advanced.html">StreamWriter Advanced Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/nvdec_tutorial.html">Accelerated video decoding with NVDEC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/nvenc_tutorial.html">Accelerated video encoding with NVENC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/effector_tutorial.html">AudioEffector Usages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/audio_resampling_tutorial.html">Audio Resampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/audio_data_augmentation_tutorial.html">Audio Data Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/audio_feature_extractions_tutorial.html">Audio Feature Extractions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/audio_feature_augmentation_tutorial.html">Audio Feature Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/ctc_forced_alignment_api_tutorial.html">CTC forced alignment API tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/audio_datasets_tutorial.html">Audio Datasets</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Pipeline Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/speech_recognition_pipeline_tutorial.html">Speech Recognition with Wav2Vec2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/asr_inference_with_ctc_decoder_tutorial.html">ASR Inference with CTC Decoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/asr_inference_with_cuda_ctc_decoder_tutorial.html">ASR Inference with CUDA CTC Decoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/online_asr_tutorial.html">Online ASR with Emformer RNN-T</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/device_asr.html">Device ASR with Emformer RNN-T</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/forced_alignment_tutorial.html">Forced Alignment with Wav2Vec2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/forced_alignment_for_multilingual_data_tutorial.html">Forced alignment for multilingual data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/tacotron2_pipeline_tutorial.html">Text-to-Speech with Tacotron2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/mvdr_tutorial.html">Speech Enhancement with MVDR Beamforming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/hybrid_demucs_tutorial.html">Music Source Separation with Hybrid Demucs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/squim_tutorial.html">Torchaudio-Squim: Non-intrusive Speech Assessment in TorchAudio</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Training Recipes</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/pytorch/audio/tree/main/examples/asr/librispeech_conformer_rnnt">Conformer RNN-T ASR</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/pytorch/audio/tree/main/examples/asr/emformer_rnnt">Emformer RNN-T ASR</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/pytorch/audio/tree/main/examples/source_separation">Conv-TasNet Source Separation</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/pytorch/audio/tree/main/examples/hubert">HuBERT Pre-training and Fine-tuning (ASR)</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/pytorch/audio/tree/main/examples/avsr">Real-time AV-ASR</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../torchaudio.html">torchaudio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../io.html">torchaudio.io</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../functional.html">torchaudio.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../transforms.html">torchaudio.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../datasets.html">torchaudio.datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models.html">torchaudio.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models.decoder.html">torchaudio.models.decoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pipelines.html">torchaudio.pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sox_effects.html">torchaudio.sox_effects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../compliance.kaldi.html">torchaudio.compliance.kaldi</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../kaldi_io.html">torchaudio.kaldi_io</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../utils.html">torchaudio.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PyTorch Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/docs">PyTorch</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/elastic/">TorchElastic</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="http://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../index.html">Module code</a> &gt;</li>
        
      <li>torchaudio.io._stream_writer &gt;</li>
      
      <li>Old version (stable)</li>
      
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
    
    
          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torchaudio.io._stream_writer</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">BinaryIO</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchaudio</span>


<span class="k">if</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">_extension</span><span class="o">.</span><span class="n">_FFMPEG_EXT</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">ConfigBase</span> <span class="o">=</span> <span class="nb">object</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">ConfigBase</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">_extension</span><span class="o">.</span><span class="n">_FFMPEG_EXT</span><span class="o">.</span><span class="n">CodecConfig</span>
    <span class="n">_StreamWriter</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">_extension</span><span class="o">.</span><span class="n">_FFMPEG_EXT</span><span class="o">.</span><span class="n">StreamWriter</span>
    <span class="n">_StreamWriterFileObj</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">_extension</span><span class="o">.</span><span class="n">_FFMPEG_EXT</span><span class="o">.</span><span class="n">StreamWriterFileObj</span>


<div class="viewcode-block" id="CodecConfig"><a class="viewcode-back" href="../../../generated/torchaudio.io.StreamWriter.html#torchaudio.io.CodecConfig">[docs]</a><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">CodecConfig</span><span class="p">(</span><span class="n">ConfigBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Codec configuration.&quot;&quot;&quot;</span>

    <span class="n">bit_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Bit rate&quot;&quot;&quot;</span>

    <span class="n">compression_level</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compression level&quot;&quot;&quot;</span>

    <span class="n">qscale</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Global quality factor. Enables variable bit rate. Valid values depend on encoder.</span>

<span class="sd">    For example: MP3 takes ``0`` - ``9`` (https://trac.ffmpeg.org/wiki/Encode/MP3) while</span>
<span class="sd">    libvorbis takes ``-1`` - ``10``.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">gop_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The number of pictures in a group of pictures, or 0 for intra_only&quot;&quot;&quot;</span>

    <span class="n">max_b_frames</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;maximum number of B-frames between non-B-frames.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bit_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">compression_level</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">qscale</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gop_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_b_frames</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_format_doc</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">decorator</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
        <span class="n">obj</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="vm">__doc__</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">obj</span>

    <span class="k">return</span> <span class="n">decorator</span>


<span class="n">_encoder</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;The name of the encoder to be used.</span>
<span class="s2">                When provided, use the specified encoder instead of the default one.</span>

<span class="s2">                To list the available encoders, please use</span>
<span class="s2">                :py:func:`~torchaudio.utils.ffmpeg_utils.get_audio_encoders` for audio, and</span>
<span class="s2">                :py:func:`~torchaudio.utils.ffmpeg_utils.get_video_encoders` for video.</span>

<span class="s2">                Default: ``None``.&quot;&quot;&quot;</span>


<span class="n">_encoder_option</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Options passed to encoder.</span>
<span class="s2">                Mapping from str to str.</span>

<span class="s2">                To list encoder options for a encoder, you can use</span>
<span class="s2">                ``ffmpeg -h encoder=&lt;ENCODER&gt;`` command.</span>

<span class="s2">                Default: ``None``.</span>

<span class="s2">                |</span>

<span class="s2">                In addition to encoder-specific options, you can also pass options related</span>
<span class="s2">                to multithreading. They are effective only if the encoder support them.</span>
<span class="s2">                If neither of them are provided, StreamReader defaults to single thread.</span>

<span class="s2">                ``&quot;threads&quot;``: The number of threads (in str).</span>
<span class="s2">                Providing the value ``&quot;0&quot;`` will let FFmpeg decides based on its heuristics.</span>

<span class="s2">                ``&quot;thread_type&quot;``: Which multithreading method to use.</span>
<span class="s2">                The valid values are ``&quot;frame&quot;`` or ``&quot;slice&quot;``.</span>
<span class="s2">                Note that each encoder supports different set of methods.</span>
<span class="s2">                If not provided, a default value is used.</span>

<span class="s2">                - ``&quot;frame&quot;``: Encode more than one frame at once.</span>
<span class="s2">                  Each thread handles one frame.</span>
<span class="s2">                  This will increase decoding delay by one frame per thread</span>
<span class="s2">                - ``&quot;slice&quot;``: Encode more than one part of a single frame at once.</span>

<span class="s2">                |</span>
<span class="s2">                &quot;&quot;&quot;</span>


<span class="n">_encoder_format</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Format used to encode media.</span>
<span class="s2">                When encoder supports multiple formats, passing this argument will override</span>
<span class="s2">                the format used for encoding.</span>

<span class="s2">                To list supported formats for the encoder, you can use</span>
<span class="s2">                ``ffmpeg -h encoder=&lt;ENCODER&gt;`` command.</span>

<span class="s2">                Default: ``None``.</span>

<span class="s2">                Note:</span>
<span class="s2">                    When ``encoder_format`` option is not provided, encoder uses its default format.</span>

<span class="s2">                    For example, when encoding audio into wav format, 16-bit signed integer is used,</span>
<span class="s2">                    and when encoding video into mp4 format (h264 encoder), one of YUV format is used.</span>

<span class="s2">                    This is because typically, 32-bit or 16-bit floating point is used in audio models but</span>
<span class="s2">                    they are not commonly used in audio formats. Similarly, RGB24 is commonly used in vision</span>
<span class="s2">                    models, but video formats usually (and better) support YUV formats.</span>
<span class="s2">                &quot;&quot;&quot;</span>

<span class="n">_codec_config</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Codec configuration. Please refer to :py:class:`CodecConfig` for</span>
<span class="s2">                configuration options.</span>

<span class="s2">                Default: ``None``.&quot;&quot;&quot;</span>


<span class="n">_filter_desc</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Additional processing to apply before encoding the input media.</span>
<span class="s2">                &quot;&quot;&quot;</span>

<span class="n">_format_common_args</span> <span class="o">=</span> <span class="n">_format_doc</span><span class="p">(</span>
    <span class="n">encoder</span><span class="o">=</span><span class="n">_encoder</span><span class="p">,</span>
    <span class="n">encoder_option</span><span class="o">=</span><span class="n">_encoder_option</span><span class="p">,</span>
    <span class="n">encoder_format</span><span class="o">=</span><span class="n">_encoder_format</span><span class="p">,</span>
    <span class="n">codec_config</span><span class="o">=</span><span class="n">_codec_config</span><span class="p">,</span>
    <span class="n">filter_desc</span><span class="o">=</span><span class="n">_filter_desc</span><span class="p">,</span>
<span class="p">)</span>


<div class="viewcode-block" id="StreamWriter"><a class="viewcode-back" href="../../../generated/torchaudio.io.StreamWriter.html#torchaudio.io.StreamWriter">[docs]</a><span class="nd">@torchaudio</span><span class="o">.</span><span class="n">_extension</span><span class="o">.</span><span class="n">fail_if_no_ffmpeg</span>
<span class="k">class</span> <span class="nc">StreamWriter</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Encode and write audio/video streams chunk by chunk</span>

<span class="sd">    Args:</span>
<span class="sd">        dst (str or file-like object): The destination where the encoded data are written.</span>
<span class="sd">            If string-type, it must be a resource indicator that FFmpeg can</span>
<span class="sd">            handle. The supported value depends on the FFmpeg found in the system.</span>

<span class="sd">            If file-like object, it must support `write` method with the signature</span>
<span class="sd">            `write(data: bytes) -&gt; int`.</span>

<span class="sd">            Please refer to the following for the expected signature and behavior of</span>
<span class="sd">            `write` method.</span>

<span class="sd">            - https://docs.python.org/3/library/io.html#io.BufferedIOBase.write</span>

<span class="sd">        format (str or None, optional):</span>
<span class="sd">            Override the output format, or specify the output media device.</span>
<span class="sd">            Default: ``None`` (no override nor device output).</span>

<span class="sd">            This argument serves two different use cases.</span>

<span class="sd">            1) Override the output format.</span>
<span class="sd">               This is useful when writing raw data or in a format different from the extension.</span>

<span class="sd">            2) Specify the output device.</span>
<span class="sd">               This allows to output media streams to hardware devices,</span>
<span class="sd">               such as speaker and video screen.</span>

<span class="sd">            .. note::</span>

<span class="sd">               This option roughly corresponds to ``-f`` option of ``ffmpeg`` command.</span>
<span class="sd">               Please refer to the ffmpeg documentations for possible values.</span>

<span class="sd">               https://ffmpeg.org/ffmpeg-formats.html#Muxers</span>

<span class="sd">               Please use :py:func:`~torchaudio.utils.ffmpeg_utils.get_muxers` to list the</span>
<span class="sd">               multiplexers available in the current environment.</span>

<span class="sd">               For device access, the available values vary based on hardware (AV device) and</span>
<span class="sd">               software configuration (ffmpeg build).</span>
<span class="sd">               Please refer to the ffmpeg documentations for possible values.</span>

<span class="sd">               https://ffmpeg.org/ffmpeg-devices.html#Output-Devices</span>

<span class="sd">               Please use :py:func:`~torchaudio.utils.ffmpeg_utils.get_output_devices` to list</span>
<span class="sd">               the output devices available in the current environment.</span>

<span class="sd">        buffer_size (int):</span>
<span class="sd">            The internal buffer size in byte. Used only when `dst` is a file-like object.</span>

<span class="sd">            Default: `4096`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dst</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">BinaryIO</span><span class="p">],</span>
        <span class="nb">format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">buffer_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4096</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dst</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_s</span> <span class="o">=</span> <span class="n">_StreamWriter</span><span class="p">(</span><span class="n">dst</span><span class="p">,</span> <span class="nb">format</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">dst</span><span class="p">,</span> <span class="s2">&quot;write&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_s</span> <span class="o">=</span> <span class="n">_StreamWriterFileObj</span><span class="p">(</span><span class="n">dst</span><span class="p">,</span> <span class="nb">format</span><span class="p">,</span> <span class="n">buffer_size</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`dst` must be either a string or a file-like object.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_open</span> <span class="o">=</span> <span class="kc">False</span>

<div class="viewcode-block" id="StreamWriter.add_audio_stream"><a class="viewcode-back" href="../../../generated/torchaudio.io.StreamWriter.html#torchaudio.io.StreamWriter.add_audio_stream">[docs]</a>    <span class="nd">@_format_common_args</span>
    <span class="k">def</span> <span class="nf">add_audio_stream</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="nb">format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;flt&quot;</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">encoder</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">encoder_option</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">encoder_sample_rate</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">encoder_num_channels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">encoder_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">codec_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">CodecConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">filter_desc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Add an output audio stream.</span>

<span class="sd">        Args:</span>
<span class="sd">            sample_rate (int): The sample rate.</span>

<span class="sd">            num_channels (int): The number of channels.</span>

<span class="sd">            format (str, optional): Input sample format, which determines the dtype</span>
<span class="sd">                of the input tensor.</span>

<span class="sd">                - ``&quot;u8&quot;``: The input tensor must be ``torch.uint8`` type.</span>
<span class="sd">                - ``&quot;s16&quot;``: The input tensor must be ``torch.int16`` type.</span>
<span class="sd">                - ``&quot;s32&quot;``: The input tensor must be ``torch.int32`` type.</span>
<span class="sd">                - ``&quot;s64&quot;``: The input tensor must be ``torch.int64`` type.</span>
<span class="sd">                - ``&quot;flt&quot;``: The input tensor must be ``torch.float32`` type.</span>
<span class="sd">                - ``&quot;dbl&quot;``: The input tensor must be ``torch.float64`` type.</span>

<span class="sd">                Default: ``&quot;flt&quot;``.</span>

<span class="sd">            encoder (str or None, optional): {encoder}</span>

<span class="sd">            encoder_option (dict or None, optional): {encoder_option}</span>

<span class="sd">            encoder_sample_rate (int or None, optional): Override the sample rate used for encoding time.</span>
<span class="sd">                Some encoders pose restriction on the sample rate used for encoding.</span>
<span class="sd">                If the source sample rate is not supported by the encoder, the source sample rate is used,</span>
<span class="sd">                otherwise a default one is picked.</span>

<span class="sd">                For example, ``&quot;opus&quot;`` encoder only supports 48k Hz, so, when encoding a</span>
<span class="sd">                waveform with ``&quot;opus&quot;`` encoder, it is always encoded as 48k Hz.</span>
<span class="sd">                Meanwhile ``&quot;mp3&quot;`` (``&quot;libmp3lame&quot;``) supports 44.1k, 48k, 32k, 22.05k,</span>
<span class="sd">                24k, 16k, 11.025k, 12k and 8k Hz.</span>
<span class="sd">                If the original sample rate is one of these, then the original sample rate</span>
<span class="sd">                is used, otherwise it will be resampled to a default one (44.1k).</span>
<span class="sd">                When encoding into WAV format, there is no restriction on sample rate,</span>
<span class="sd">                so the original sample rate will be used.</span>

<span class="sd">                Providing ``encoder_sample_rate`` will override this behavior and</span>
<span class="sd">                make encoder attempt to use the provided sample rate.</span>
<span class="sd">                The provided value must be one support by the encoder.</span>

<span class="sd">            encoder_num_channels (int or None, optional): Override the number of channels used for encoding.</span>

<span class="sd">                Similar to sample rate, some encoders (such as ``&quot;opus&quot;``,</span>
<span class="sd">                ``&quot;vorbis&quot;`` and ``&quot;g722&quot;``) pose restriction on</span>
<span class="sd">                the numbe of channels that can be used for encoding.</span>

<span class="sd">                If the original number of channels is supported by encoder,</span>
<span class="sd">                then it will be used, otherwise, the encoder attempts to</span>
<span class="sd">                remix the channel to one of the supported ones.</span>

<span class="sd">                Providing ``encoder_num_channels`` will override this behavior and</span>
<span class="sd">                make encoder attempt to use the provided number of channels.</span>
<span class="sd">                The provided value must be one support by the encoder.</span>

<span class="sd">            encoder_format (str or None, optional): {encoder_format}</span>

<span class="sd">            codec_config (CodecConfig or None, optional): {codec_config}</span>

<span class="sd">            filter_desc (str or None, optional): {filter_desc}</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_s</span><span class="o">.</span><span class="n">add_audio_stream</span><span class="p">(</span>
            <span class="n">sample_rate</span><span class="p">,</span>
            <span class="n">num_channels</span><span class="p">,</span>
            <span class="nb">format</span><span class="p">,</span>
            <span class="n">encoder</span><span class="p">,</span>
            <span class="n">encoder_option</span><span class="p">,</span>
            <span class="n">encoder_format</span><span class="p">,</span>
            <span class="n">encoder_sample_rate</span><span class="p">,</span>
            <span class="n">encoder_num_channels</span><span class="p">,</span>
            <span class="n">codec_config</span><span class="p">,</span>
            <span class="n">filter_desc</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="StreamWriter.add_video_stream"><a class="viewcode-back" href="../../../generated/torchaudio.io.StreamWriter.html#torchaudio.io.StreamWriter.add_video_stream">[docs]</a>    <span class="nd">@_format_common_args</span>
    <span class="k">def</span> <span class="nf">add_video_stream</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">frame_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">width</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">height</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="nb">format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;rgb24&quot;</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">encoder</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">encoder_option</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">encoder_frame_rate</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">encoder_width</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">encoder_height</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">encoder_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">codec_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">CodecConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">filter_desc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">hw_accel</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Add an output video stream.</span>

<span class="sd">        This method has to be called before `open` is called.</span>

<span class="sd">        Args:</span>
<span class="sd">            frame_rate (float): Frame rate of the video.</span>

<span class="sd">            width (int): Width of the video frame.</span>

<span class="sd">            height (int): Height of the video frame.</span>

<span class="sd">            format (str, optional): Input pixel format, which determines the</span>
<span class="sd">                color channel order of the input tensor.</span>

<span class="sd">                - ``&quot;gray8&quot;``: One channel, grayscale.</span>
<span class="sd">                - ``&quot;rgb24&quot;``: Three channels in the order of RGB.</span>
<span class="sd">                - ``&quot;bgr24&quot;``: Three channels in the order of BGR.</span>
<span class="sd">                - ``&quot;yuv444p&quot;``: Three channels in the order of YUV.</span>

<span class="sd">                Default: ``&quot;rgb24&quot;``.</span>

<span class="sd">                In either case, the input tensor has to be ``torch.uint8`` type and</span>
<span class="sd">                the shape must be (frame, channel, height, width).</span>

<span class="sd">            encoder (str or None, optional): {encoder}</span>

<span class="sd">            encoder_option (dict or None, optional): {encoder_option}</span>

<span class="sd">            encoder_frame_rate (float or None, optional): Override the frame rate used for encoding.</span>

<span class="sd">                Some encoders, (such as ``&quot;mpeg1&quot;`` and ``&quot;mpeg2&quot;``) pose restriction on the</span>
<span class="sd">                frame rate that can be used for encoding.</span>
<span class="sd">                If such case, if the source frame rate (provided as ``frame_rate``) is not</span>
<span class="sd">                one of the supported frame rate, then a default one is picked, and the frame rate</span>
<span class="sd">                is changed on-the-fly. Otherwise the source frame rate is used.</span>

<span class="sd">                Providing ``encoder_frame_rate`` will override this behavior and</span>
<span class="sd">                make encoder attempts to use the provided sample rate.</span>
<span class="sd">                The provided value must be one support by the encoder.</span>

<span class="sd">            encoder_width (int or None, optional): Width of the image used for encoding.</span>
<span class="sd">                This allows to change the image size during encoding.</span>

<span class="sd">            encoder_height (int or None, optional): Height of the image used for encoding.</span>
<span class="sd">                This allows to change the image size during encoding.</span>

<span class="sd">            encoder_format (str or None, optional): {encoder_format}</span>

<span class="sd">            codec_config (CodecConfig or None, optional): {codec_config}</span>

<span class="sd">            filter_desc (str or None, optional): {filter_desc}</span>

<span class="sd">            hw_accel (str or None, optional): Enable hardware acceleration.</span>

<span class="sd">                When video is encoded on CUDA hardware, for example</span>
<span class="sd">                `encoder=&quot;h264_nvenc&quot;`, passing CUDA device indicator to `hw_accel`</span>
<span class="sd">                (i.e. `hw_accel=&quot;cuda:0&quot;`) will make StreamWriter expect video</span>
<span class="sd">                chunk to be CUDA Tensor. Passing CPU Tensor will result in an error.</span>

<span class="sd">                If `None`, the video chunk Tensor has to be CPU Tensor.</span>
<span class="sd">                Default: ``None``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_s</span><span class="o">.</span><span class="n">add_video_stream</span><span class="p">(</span>
            <span class="n">frame_rate</span><span class="p">,</span>
            <span class="n">width</span><span class="p">,</span>
            <span class="n">height</span><span class="p">,</span>
            <span class="nb">format</span><span class="p">,</span>
            <span class="n">encoder</span><span class="p">,</span>
            <span class="n">encoder_option</span><span class="p">,</span>
            <span class="n">encoder_format</span><span class="p">,</span>
            <span class="n">encoder_frame_rate</span><span class="p">,</span>
            <span class="n">encoder_width</span><span class="p">,</span>
            <span class="n">encoder_height</span><span class="p">,</span>
            <span class="n">hw_accel</span><span class="p">,</span>
            <span class="n">codec_config</span><span class="p">,</span>
            <span class="n">filter_desc</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="StreamWriter.set_metadata"><a class="viewcode-back" href="../../../generated/torchaudio.io.StreamWriter.html#torchaudio.io.StreamWriter.set_metadata">[docs]</a>    <span class="k">def</span> <span class="nf">set_metadata</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metadata</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set file-level metadata</span>

<span class="sd">        Args:</span>
<span class="sd">            metadata (dict or None, optional): File-level metadata.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_s</span><span class="o">.</span><span class="n">set_metadata</span><span class="p">(</span><span class="n">metadata</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_print_output_stream</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;[debug] Print the registered stream information to stdout.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_s</span><span class="o">.</span><span class="n">dump_format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

<div class="viewcode-block" id="StreamWriter.open"><a class="viewcode-back" href="../../../generated/torchaudio.io.StreamWriter.html#torchaudio.io.StreamWriter.open">[docs]</a>    <span class="k">def</span> <span class="nf">open</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">option</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;StreamWriter&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Open the output file / device and write the header.</span>

<span class="sd">        :py:class:`StreamWriter` is also a context manager and therefore supports the</span>
<span class="sd">        ``with`` statement.</span>
<span class="sd">        This method returns the instance on which the method is called (i.e. `self`),</span>
<span class="sd">        so that it can be used in `with` statement.</span>
<span class="sd">        It is recommended to use context manager, as the file is closed automatically</span>
<span class="sd">        when exiting from ``with`` clause.</span>

<span class="sd">        Args:</span>
<span class="sd">            option (dict or None, optional): Private options for protocol, device and muxer. See example.</span>

<span class="sd">        Example - Protocol option</span>
<span class="sd">            &gt;&gt;&gt; s = StreamWriter(dst=&quot;rtmp://localhost:1234/live/app&quot;, format=&quot;flv&quot;)</span>
<span class="sd">            &gt;&gt;&gt; s.add_video_stream(...)</span>
<span class="sd">            &gt;&gt;&gt; # Passing protocol option `listen=1` makes StreamWriter act as RTMP server.</span>
<span class="sd">            &gt;&gt;&gt; with s.open(option={&quot;listen&quot;: &quot;1&quot;}) as f:</span>
<span class="sd">            &gt;&gt;&gt;     f.write_video_chunk(...)</span>

<span class="sd">        Example - Device option</span>
<span class="sd">            &gt;&gt;&gt; s = StreamWriter(&quot;-&quot;, format=&quot;sdl&quot;)</span>
<span class="sd">            &gt;&gt;&gt; s.add_video_stream(..., encoder_format=&quot;rgb24&quot;)</span>
<span class="sd">            &gt;&gt;&gt; # Open SDL video player with fullscreen</span>
<span class="sd">            &gt;&gt;&gt; with s.open(option={&quot;window_fullscreen&quot;: &quot;1&quot;}):</span>
<span class="sd">            &gt;&gt;&gt;     f.write_video_chunk(...)</span>

<span class="sd">        Example - Muxer option</span>
<span class="sd">            &gt;&gt;&gt; s = StreamWriter(&quot;foo.flac&quot;)</span>
<span class="sd">            &gt;&gt;&gt; s.add_audio_stream(...)</span>
<span class="sd">            &gt;&gt;&gt; s.set_metadata({&quot;artist&quot;: &quot;torchaudio contributors&quot;})</span>
<span class="sd">            &gt;&gt;&gt; # FLAC muxer has a private option to not write the header.</span>
<span class="sd">            &gt;&gt;&gt; # The resulting file does not contain the above metadata.</span>
<span class="sd">            &gt;&gt;&gt; with s.open(option={&quot;write_header&quot;: &quot;false&quot;}) as f:</span>
<span class="sd">            &gt;&gt;&gt;     f.write_audio_chunk(...)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_open</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_s</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">option</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_is_open</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="StreamWriter.close"><a class="viewcode-back" href="../../../generated/torchaudio.io.StreamWriter.html#torchaudio.io.StreamWriter.close">[docs]</a>    <span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Close the output</span>

<span class="sd">        :py:class:`StreamWriter` is also a context manager and therefore supports the</span>
<span class="sd">        ``with`` statement.</span>
<span class="sd">        It is recommended to use context manager, as the file is closed automatically</span>
<span class="sd">        when exiting from ``with`` clause.</span>

<span class="sd">        See :py:meth:`StreamWriter.open` for more detail.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_open</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_s</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_is_open</span> <span class="o">=</span> <span class="kc">False</span></div>

<div class="viewcode-block" id="StreamWriter.write_audio_chunk"><a class="viewcode-back" href="../../../generated/torchaudio.io.StreamWriter.html#torchaudio.io.StreamWriter.write_audio_chunk">[docs]</a>    <span class="k">def</span> <span class="nf">write_audio_chunk</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">chunk</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">pts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Write audio data</span>

<span class="sd">        Args:</span>
<span class="sd">            i (int): Stream index.</span>
<span class="sd">            chunk (Tensor): Waveform tensor. Shape: `(frame, channel)`.</span>
<span class="sd">                The ``dtype`` must match what was passed to :py:meth:`add_audio_stream` method.</span>
<span class="sd">            pts (float, optional, or None): If provided, overwrite the presentation timestamp.</span>

<span class="sd">                .. note::</span>

<span class="sd">                   The provided value is converted to integer value expressed in basis of</span>
<span class="sd">                   sample rate. Therefore, it is truncated to the nearest value of</span>
<span class="sd">                   ``n / sample_rate``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_s</span><span class="o">.</span><span class="n">write_audio_chunk</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">chunk</span><span class="p">,</span> <span class="n">pts</span><span class="p">)</span></div>

<div class="viewcode-block" id="StreamWriter.write_video_chunk"><a class="viewcode-back" href="../../../generated/torchaudio.io.StreamWriter.html#torchaudio.io.StreamWriter.write_video_chunk">[docs]</a>    <span class="k">def</span> <span class="nf">write_video_chunk</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">chunk</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">pts</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Write video/image data</span>

<span class="sd">        Args:</span>
<span class="sd">            i (int): Stream index.</span>
<span class="sd">            chunk (Tensor): Video/image tensor.</span>
<span class="sd">                Shape: `(time, channel, height, width)`.</span>
<span class="sd">                The ``dtype`` must be ``torch.uint8``.</span>
<span class="sd">                The shape (height, width and the number of channels) must match</span>
<span class="sd">                what was configured when calling :py:meth:`add_video_stream`</span>
<span class="sd">            pts (float, optional or None): If provided, overwrite the presentation timestamp.</span>

<span class="sd">                .. note::</span>

<span class="sd">                   The provided value is converted to integer value expressed in basis of</span>
<span class="sd">                   frame rate. Therefore, it is truncated to the nearest value of</span>
<span class="sd">                   ``n / frame_rate``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_s</span><span class="o">.</span><span class="n">write_video_chunk</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">chunk</span><span class="p">,</span> <span class="n">pts</span><span class="p">)</span></div>

<div class="viewcode-block" id="StreamWriter.flush"><a class="viewcode-back" href="../../../generated/torchaudio.io.StreamWriter.html#torchaudio.io.StreamWriter.flush">[docs]</a>    <span class="k">def</span> <span class="nf">flush</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Flush the frames from encoders and write the frames to the destination.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_s</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span></div>

    <span class="k">def</span> <span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Context manager so that the destination is closed and data are flushed automatically.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="fm">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exception_type</span><span class="p">,</span> <span class="n">exception_value</span><span class="p">,</span> <span class="n">traceback</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Context manager so that the destination is closed and data are flushed automatically.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">close</span><span class="p">()</span></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2023, Torchaudio Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>


        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
         <script src="../../../_static/jquery.js"></script>
         <script src="../../../_static/underscore.js"></script>
         <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../_static/doctools.js"></script>
         <script src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.js"></script>
         <script src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/contrib/auto-render.min.js"></script>
         <script src="../../../_static/katex_autorenderer.js"></script>
     

  

  <script type="text/javascript" src="../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <script type="text/javascript">
    var collapsedSections = ['API Tutorials', 'Pipeline Tutorials', 'Training Recipes']
    </script>
     
    <script type="text/javascript">
      $(document).ready(function() {
	  var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
	  if (downloadNote.length >= 1) {
	      var tutorialUrl = $("#tutorial-type").text();
	      var githubLink = "https://github.com/pytorch/audio/blob/main/examples/"  + tutorialUrl + ".py",
		  notebookLink = $(".reference.download")[1].href,
		  notebookDownloadPath = notebookLink.split('_downloads')[1],
		  colabLink = "https://colab.research.google.com/github/pytorch/audio/blob/gh-pages/main/_downloads" + notebookDownloadPath;

	      $(".pytorch-call-to-action-links a[data-response='Run in Google Colab']").attr("href", colabLink);
	      $(".pytorch-call-to-action-links a[data-response='View on Github']").attr("href", githubLink);
	  }

          var overwrite = function(_) {
              if ($(this).length > 0) {
                  $(this)[0].href = "https://github.com/pytorch/audio"
              }
          }
          // PC
          $(".main-menu a:contains('GitHub')").each(overwrite);
          // Mobile
          $(".main-menu a:contains('Github')").each(overwrite);
      });

      
       $(window).ready(function() {
           var original = window.sideMenus.bind;
           var startup = true;
           window.sideMenus.bind = function() {
               original();
               if (startup) {
                   $("#pytorch-right-menu a.reference.internal").each(function(i) {
                       if (this.classList.contains("not-expanded")) {
                           this.nextElementSibling.style.display = "block";
                           this.classList.remove("not-expanded");
                           this.classList.add("expanded");
                       }
                   });
                   startup = false;
               }
           };
       });
    </script>

    


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>Â© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>
            
          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>
            
           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>