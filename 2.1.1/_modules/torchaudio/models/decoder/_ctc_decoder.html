


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchaudio.models.decoder._ctc_decoder &mdash; Torchaudio 2.1.1 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../../../_static/favicon.ico"/>
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="../../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href="../../../../../versions.html"><span style="font-size:110%">2.1.1 &#x25BC</span></a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Torchaudio Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../index.html">Index</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../supported_features.html">Supported Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../feature_classifications.html">Feature Classifications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../logo.html">TorchAudio Logo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../references.html">References</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../installation.html">Installing pre-built binaries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../build.html">Building from source</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../build.linux.html">Building on Linux and macOS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../build.windows.html">Building on Windows</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../build.jetson.html">Building on Jetson</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../build.ffmpeg.html">Enabling GPU video decoder/encoder</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/audio_io_tutorial.html">Audio I/O</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/streamreader_basic_tutorial.html">StreamReader Basic Usages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/streamreader_advanced_tutorial.html">StreamReader Advanced Usages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/streamwriter_basic_tutorial.html">StreamWriter Basic Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/streamwriter_advanced.html">StreamWriter Advanced Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/nvdec_tutorial.html">Accelerated video decoding with NVDEC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/nvenc_tutorial.html">Accelerated video encoding with NVENC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/effector_tutorial.html">AudioEffector Usages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/audio_resampling_tutorial.html">Audio Resampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/audio_data_augmentation_tutorial.html">Audio Data Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/audio_feature_extractions_tutorial.html">Audio Feature Extractions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/audio_feature_augmentation_tutorial.html">Audio Feature Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/ctc_forced_alignment_api_tutorial.html">CTC forced alignment API tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/audio_datasets_tutorial.html">Audio Datasets</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Pipeline Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/speech_recognition_pipeline_tutorial.html">Speech Recognition with Wav2Vec2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/asr_inference_with_ctc_decoder_tutorial.html">ASR Inference with CTC Decoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/asr_inference_with_cuda_ctc_decoder_tutorial.html">ASR Inference with CUDA CTC Decoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/online_asr_tutorial.html">Online ASR with Emformer RNN-T</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/device_asr.html">Device ASR with Emformer RNN-T</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/forced_alignment_tutorial.html">Forced Alignment with Wav2Vec2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/forced_alignment_for_multilingual_data_tutorial.html">Forced alignment for multilingual data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/tacotron2_pipeline_tutorial.html">Text-to-Speech with Tacotron2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/mvdr_tutorial.html">Speech Enhancement with MVDR Beamforming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/hybrid_demucs_tutorial.html">Music Source Separation with Hybrid Demucs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/squim_tutorial.html">Torchaudio-Squim: Non-intrusive Speech Assessment in TorchAudio</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Training Recipes</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/pytorch/audio/tree/main/examples/asr/librispeech_conformer_rnnt">Conformer RNN-T ASR</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/pytorch/audio/tree/main/examples/asr/emformer_rnnt">Emformer RNN-T ASR</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/pytorch/audio/tree/main/examples/source_separation">Conv-TasNet Source Separation</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/pytorch/audio/tree/main/examples/hubert">HuBERT Pre-training and Fine-tuning (ASR)</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/pytorch/audio/tree/main/examples/avsr">Real-time AV-ASR</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../torchaudio.html">torchaudio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../io.html">torchaudio.io</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional.html">torchaudio.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../transforms.html">torchaudio.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../datasets.html">torchaudio.datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../models.html">torchaudio.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../models.decoder.html">torchaudio.models.decoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../pipelines.html">torchaudio.pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sox_effects.html">torchaudio.sox_effects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../compliance.kaldi.html">torchaudio.compliance.kaldi</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../kaldi_io.html">torchaudio.kaldi_io</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../utils.html">torchaudio.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PyTorch Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/docs">PyTorch</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/elastic/">TorchElastic</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="http://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../index.html">Module code</a> &gt;</li>
        
      <li>torchaudio.models.decoder._ctc_decoder &gt;</li>
      
      <li>Old version (stable)</li>
      
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
    
    
          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torchaudio.models.decoder._ctc_decoder</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span> <span class="nn">itertools</span> <span class="k">as</span> <span class="nn">it</span>

<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">NamedTuple</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">flashlight.lib.text.decoder</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">CriterionType</span> <span class="k">as</span> <span class="n">_CriterionType</span><span class="p">,</span>
    <span class="n">LexiconDecoder</span> <span class="k">as</span> <span class="n">_LexiconDecoder</span><span class="p">,</span>
    <span class="n">LexiconDecoderOptions</span> <span class="k">as</span> <span class="n">_LexiconDecoderOptions</span><span class="p">,</span>
    <span class="n">LexiconFreeDecoder</span> <span class="k">as</span> <span class="n">_LexiconFreeDecoder</span><span class="p">,</span>
    <span class="n">LexiconFreeDecoderOptions</span> <span class="k">as</span> <span class="n">_LexiconFreeDecoderOptions</span><span class="p">,</span>
    <span class="n">LM</span> <span class="k">as</span> <span class="n">_LM</span><span class="p">,</span>
    <span class="n">LMState</span> <span class="k">as</span> <span class="n">_LMState</span><span class="p">,</span>
    <span class="n">SmearingMode</span> <span class="k">as</span> <span class="n">_SmearingMode</span><span class="p">,</span>
    <span class="n">Trie</span> <span class="k">as</span> <span class="n">_Trie</span><span class="p">,</span>
    <span class="n">ZeroLM</span> <span class="k">as</span> <span class="n">_ZeroLM</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">flashlight.lib.text.dictionary</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">create_word_dict</span> <span class="k">as</span> <span class="n">_create_word_dict</span><span class="p">,</span>
    <span class="n">Dictionary</span> <span class="k">as</span> <span class="n">_Dictionary</span><span class="p">,</span>
    <span class="n">load_words</span> <span class="k">as</span> <span class="n">_load_words</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">torchaudio.utils</span> <span class="kn">import</span> <span class="n">download_asset</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">flashlight.lib.text.decoder.kenlm</span> <span class="kn">import</span> <span class="n">KenLM</span> <span class="k">as</span> <span class="n">_KenLM</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">flashlight.lib.text.decoder</span> <span class="kn">import</span> <span class="n">KenLM</span> <span class="k">as</span> <span class="n">_KenLM</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="n">_KenLM</span> <span class="o">=</span> <span class="kc">None</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;CTCHypothesis&quot;</span><span class="p">,</span>
    <span class="s2">&quot;CTCDecoder&quot;</span><span class="p">,</span>
    <span class="s2">&quot;CTCDecoderLM&quot;</span><span class="p">,</span>
    <span class="s2">&quot;CTCDecoderLMState&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ctc_decoder&quot;</span><span class="p">,</span>
    <span class="s2">&quot;download_pretrained_files&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">_PretrainedFiles</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">&quot;PretrainedFiles&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;lexicon&quot;</span><span class="p">,</span> <span class="s2">&quot;tokens&quot;</span><span class="p">,</span> <span class="s2">&quot;lm&quot;</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">_construct_trie</span><span class="p">(</span><span class="n">tokens_dict</span><span class="p">,</span> <span class="n">word_dict</span><span class="p">,</span> <span class="n">lexicon</span><span class="p">,</span> <span class="n">lm</span><span class="p">,</span> <span class="n">silence</span><span class="p">):</span>
    <span class="n">vocab_size</span> <span class="o">=</span> <span class="n">tokens_dict</span><span class="o">.</span><span class="n">index_size</span><span class="p">()</span>
    <span class="n">trie</span> <span class="o">=</span> <span class="n">_Trie</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">silence</span><span class="p">)</span>
    <span class="n">start_state</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">spellings</span> <span class="ow">in</span> <span class="n">lexicon</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">word_idx</span> <span class="o">=</span> <span class="n">word_dict</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">score</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">start_state</span><span class="p">,</span> <span class="n">word_idx</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">spelling</span> <span class="ow">in</span> <span class="n">spellings</span><span class="p">:</span>
            <span class="n">spelling_idx</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokens_dict</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">spelling</span><span class="p">]</span>
            <span class="n">trie</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">spelling_idx</span><span class="p">,</span> <span class="n">word_idx</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span>
    <span class="n">trie</span><span class="o">.</span><span class="n">smear</span><span class="p">(</span><span class="n">_SmearingMode</span><span class="o">.</span><span class="n">MAX</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">trie</span>


<span class="k">def</span> <span class="nf">_get_word_dict</span><span class="p">(</span><span class="n">lexicon</span><span class="p">,</span> <span class="n">lm</span><span class="p">,</span> <span class="n">lm_dict</span><span class="p">,</span> <span class="n">tokens_dict</span><span class="p">,</span> <span class="n">unk_word</span><span class="p">):</span>
    <span class="n">word_dict</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">lm_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">word_dict</span> <span class="o">=</span> <span class="n">_Dictionary</span><span class="p">(</span><span class="n">lm_dict</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">lexicon</span> <span class="ow">and</span> <span class="n">word_dict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">word_dict</span> <span class="o">=</span> <span class="n">_create_word_dict</span><span class="p">(</span><span class="n">lexicon</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="n">lexicon</span> <span class="ow">and</span> <span class="n">word_dict</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">type</span><span class="p">(</span><span class="n">lm</span><span class="p">)</span> <span class="o">==</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">d</span> <span class="o">=</span> <span class="p">{</span><span class="n">tokens_dict</span><span class="o">.</span><span class="n">get_entry</span><span class="p">(</span><span class="n">i</span><span class="p">):</span> <span class="p">[[</span><span class="n">tokens_dict</span><span class="o">.</span><span class="n">get_entry</span><span class="p">(</span><span class="n">i</span><span class="p">)]]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">tokens_dict</span><span class="o">.</span><span class="n">index_size</span><span class="p">())}</span>
        <span class="n">d</span><span class="p">[</span><span class="n">unk_word</span><span class="p">]</span> <span class="o">=</span> <span class="p">[[</span><span class="n">unk_word</span><span class="p">]]</span>
        <span class="n">word_dict</span> <span class="o">=</span> <span class="n">_create_word_dict</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">word_dict</span>


<div class="viewcode-block" id="CTCHypothesis"><a class="viewcode-back" href="../../../../generated/torchaudio.models.decoder.CTCDecoder.html#torchaudio.models.decoder.CTCHypothesis">[docs]</a><span class="k">class</span> <span class="nc">CTCHypothesis</span><span class="p">(</span><span class="n">NamedTuple</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Represents hypothesis generated by CTC beam search decoder :class:`CTCDecoder`.&quot;&quot;&quot;</span>
    <span class="n">tokens</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Predicted sequence of token IDs. Shape `(L, )`, where `L` is the length of the output sequence&quot;&quot;&quot;</span>

    <span class="n">words</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;List of predicted words.</span>

<span class="sd">    Note:</span>
<span class="sd">        This attribute is only applicable if a lexicon is provided to the decoder. If</span>
<span class="sd">        decoding without a lexicon, it will be blank. Please refer to :attr:`tokens` and</span>
<span class="sd">        :func:`~torchaudio.models.decoder.CTCDecoder.idxs_to_tokens` instead.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">score</span><span class="p">:</span> <span class="nb">float</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Score corresponding to hypothesis&quot;&quot;&quot;</span>

    <span class="n">timesteps</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">IntTensor</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Timesteps corresponding to the tokens. Shape `(L, )`, where `L` is the length of the output sequence&quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="CTCDecoderLMState"><a class="viewcode-back" href="../../../../generated/torchaudio.models.decoder.CTCDecoder.html#torchaudio.models.decoder.CTCDecoderLMState">[docs]</a><span class="k">class</span> <span class="nc">CTCDecoderLMState</span><span class="p">(</span><span class="n">_LMState</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Language model state.&quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">children</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">CTCDecoderLMState</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Map of indices to LM states&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">children</span>

<div class="viewcode-block" id="CTCDecoderLMState.child"><a class="viewcode-back" href="../../../../generated/torchaudio.models.decoder.CTCDecoder.html#torchaudio.models.decoder.CTCDecoderLMState.child">[docs]</a>    <span class="k">def</span> <span class="nf">child</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">usr_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">CTCDecoderLMState</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns child corresponding to usr_index, or creates and returns a new state if input index</span>
<span class="sd">        is not found.</span>

<span class="sd">        Args:</span>
<span class="sd">            usr_index (int): index corresponding to child state</span>

<span class="sd">        Returns:</span>
<span class="sd">            CTCDecoderLMState: child state corresponding to usr_index</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">child</span><span class="p">(</span><span class="n">usr_index</span><span class="p">)</span></div>

<div class="viewcode-block" id="CTCDecoderLMState.compare"><a class="viewcode-back" href="../../../../generated/torchaudio.models.decoder.CTCDecoder.html#torchaudio.models.decoder.CTCDecoderLMState.compare">[docs]</a>    <span class="k">def</span> <span class="nf">compare</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">CTCDecoderLMState</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">CTCDecoderLMState</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compare two language model states.</span>

<span class="sd">        Args:</span>
<span class="sd">            state (CTCDecoderLMState): LM state to compare against</span>

<span class="sd">        Returns:</span>
<span class="sd">            int: 0 if the states are the same, -1 if self is less, +1 if self is greater.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div></div>


<div class="viewcode-block" id="CTCDecoderLM"><a class="viewcode-back" href="../../../../generated/torchaudio.models.decoder.CTCDecoder.html#torchaudio.models.decoder.CTCDecoderLM">[docs]</a><span class="k">class</span> <span class="nc">CTCDecoderLM</span><span class="p">(</span><span class="n">_LM</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Language model base class for creating custom language models to use with the decoder.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="CTCDecoderLM.start"><a class="viewcode-back" href="../../../../generated/torchaudio.models.decoder.CTCDecoder.html#torchaudio.models.decoder.CTCDecoderLM.start">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">start</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">start_with_nothing</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">CTCDecoderLMState</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize or reset the language model.</span>

<span class="sd">        Args:</span>
<span class="sd">            start_with_nothing (bool): whether or not to start sentence with sil token.</span>

<span class="sd">        Returns:</span>
<span class="sd">            CTCDecoderLMState: starting state</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="CTCDecoderLM.score"><a class="viewcode-back" href="../../../../generated/torchaudio.models.decoder.CTCDecoder.html#torchaudio.models.decoder.CTCDecoderLM.score">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">CTCDecoderLMState</span><span class="p">,</span> <span class="n">usr_token_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">CTCDecoderLMState</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluate the language model based on the current LM state and new word.</span>

<span class="sd">        Args:</span>
<span class="sd">            state (CTCDecoderLMState): current LM state</span>
<span class="sd">            usr_token_idx (int): index of the word</span>

<span class="sd">        Returns:</span>
<span class="sd">            (CTCDecoderLMState, float)</span>
<span class="sd">                CTCDecoderLMState:</span>
<span class="sd">                    new LM state</span>
<span class="sd">                float:</span>
<span class="sd">                    score</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="CTCDecoderLM.finish"><a class="viewcode-back" href="../../../../generated/torchaudio.models.decoder.CTCDecoder.html#torchaudio.models.decoder.CTCDecoderLM.finish">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">finish</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">CTCDecoderLMState</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">CTCDecoderLMState</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluate end for language model based on current LM state.</span>

<span class="sd">        Args:</span>
<span class="sd">            state (CTCDecoderLMState): current LM state</span>

<span class="sd">        Returns:</span>
<span class="sd">            (CTCDecoderLMState, float)</span>
<span class="sd">                CTCDecoderLMState:</span>
<span class="sd">                    new LM state</span>
<span class="sd">                float:</span>
<span class="sd">                    score</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div></div>


<div class="viewcode-block" id="CTCDecoder"><a class="viewcode-back" href="../../../../generated/torchaudio.models.decoder.CTCDecoder.html#torchaudio.models.decoder.CTCDecoder">[docs]</a><span class="k">class</span> <span class="nc">CTCDecoder</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;CTC beam search decoder from *Flashlight* :cite:`kahn2022flashlight`.</span>

<span class="sd">    .. devices:: CPU</span>

<span class="sd">    Note:</span>
<span class="sd">        To build the decoder, please use the factory function :func:`ctc_decoder`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">nbest</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">lexicon</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">],</span>
        <span class="n">word_dict</span><span class="p">:</span> <span class="n">_Dictionary</span><span class="p">,</span>
        <span class="n">tokens_dict</span><span class="p">:</span> <span class="n">_Dictionary</span><span class="p">,</span>
        <span class="n">lm</span><span class="p">:</span> <span class="n">CTCDecoderLM</span><span class="p">,</span>
        <span class="n">decoder_options</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">_LexiconDecoderOptions</span><span class="p">,</span> <span class="n">_LexiconFreeDecoderOptions</span><span class="p">],</span>
        <span class="n">blank_token</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">sil_token</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">unk_word</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            nbest (int): number of best decodings to return</span>
<span class="sd">            lexicon (Dict or None): lexicon mapping of words to spellings, or None for lexicon-free decoder</span>
<span class="sd">            word_dict (_Dictionary): dictionary of words</span>
<span class="sd">            tokens_dict (_Dictionary): dictionary of tokens</span>
<span class="sd">            lm (CTCDecoderLM): language model. If using a lexicon, only word level LMs are currently supported</span>
<span class="sd">            decoder_options (_LexiconDecoderOptions or _LexiconFreeDecoderOptions):</span>
<span class="sd">                parameters used for beam search decoding</span>
<span class="sd">            blank_token (str): token corresopnding to blank</span>
<span class="sd">            sil_token (str): token corresponding to silence</span>
<span class="sd">            unk_word (str): word corresponding to unknown</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">nbest</span> <span class="o">=</span> <span class="n">nbest</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word_dict</span> <span class="o">=</span> <span class="n">word_dict</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokens_dict</span> <span class="o">=</span> <span class="n">tokens_dict</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">blank</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokens_dict</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="n">blank_token</span><span class="p">)</span>
        <span class="n">silence</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokens_dict</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="n">sil_token</span><span class="p">)</span>
        <span class="n">transitions</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="n">lexicon</span><span class="p">:</span>
            <span class="n">trie</span> <span class="o">=</span> <span class="n">_construct_trie</span><span class="p">(</span><span class="n">tokens_dict</span><span class="p">,</span> <span class="n">word_dict</span><span class="p">,</span> <span class="n">lexicon</span><span class="p">,</span> <span class="n">lm</span><span class="p">,</span> <span class="n">silence</span><span class="p">)</span>
            <span class="n">unk_word</span> <span class="o">=</span> <span class="n">word_dict</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="n">unk_word</span><span class="p">)</span>
            <span class="n">token_lm</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># use word level LM</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">_LexiconDecoder</span><span class="p">(</span>
                <span class="n">decoder_options</span><span class="p">,</span>
                <span class="n">trie</span><span class="p">,</span>
                <span class="n">lm</span><span class="p">,</span>
                <span class="n">silence</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">blank</span><span class="p">,</span>
                <span class="n">unk_word</span><span class="p">,</span>
                <span class="n">transitions</span><span class="p">,</span>
                <span class="n">token_lm</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">_LexiconFreeDecoder</span><span class="p">(</span><span class="n">decoder_options</span><span class="p">,</span> <span class="n">lm</span><span class="p">,</span> <span class="n">silence</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">blank</span><span class="p">,</span> <span class="n">transitions</span><span class="p">)</span>
        <span class="c1"># https://github.com/pytorch/audio/issues/3218</span>
        <span class="c1"># If lm is passed like rvalue reference, the lm object gets garbage collected,</span>
        <span class="c1"># and later call to the lm fails.</span>
        <span class="c1"># This ensures that lm object is not deleted as long as the decoder is alive.</span>
        <span class="c1"># https://github.com/pybind/pybind11/discussions/4013</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lm</span> <span class="o">=</span> <span class="n">lm</span>

    <span class="k">def</span> <span class="nf">_get_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idxs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">IntTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">:</span>
        <span class="n">idxs</span> <span class="o">=</span> <span class="p">(</span><span class="n">g</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">it</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">idxs</span><span class="p">))</span>
        <span class="n">idxs</span> <span class="o">=</span> <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">blank</span><span class="p">,</span> <span class="n">idxs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">idxs</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_get_timesteps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idxs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">IntTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">IntTensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns frame numbers corresponding to non-blank tokens.&quot;&quot;&quot;</span>

        <span class="n">timesteps</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">idxs</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">blank</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">idx</span> <span class="o">!=</span> <span class="n">idxs</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]:</span>
                <span class="n">timesteps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">IntTensor</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span>

<div class="viewcode-block" id="CTCDecoder.decode_begin"><a class="viewcode-back" href="../../../../generated/torchaudio.models.decoder.CTCDecoder.html#torchaudio.models.decoder.CTCDecoder.decode_begin">[docs]</a>    <span class="k">def</span> <span class="nf">decode_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the internal state of the decoder.</span>

<span class="sd">        See :py:meth:`decode_step` for the usage.</span>

<span class="sd">        .. note::</span>

<span class="sd">           This method is required only when performing online decoding.</span>
<span class="sd">           It is not necessary when performing batch decoding with :py:meth:`__call__`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">decode_begin</span><span class="p">()</span></div>

<div class="viewcode-block" id="CTCDecoder.decode_end"><a class="viewcode-back" href="../../../../generated/torchaudio.models.decoder.CTCDecoder.html#torchaudio.models.decoder.CTCDecoder.decode_end">[docs]</a>    <span class="k">def</span> <span class="nf">decode_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Finalize the internal state of the decoder.</span>

<span class="sd">        See :py:meth:`decode_step` for the usage.</span>

<span class="sd">        .. note::</span>

<span class="sd">           This method is required only when performing online decoding.</span>
<span class="sd">           It is not necessary when performing batch decoding with :py:meth:`__call__`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">decode_end</span><span class="p">()</span></div>

<div class="viewcode-block" id="CTCDecoder.decode_step"><a class="viewcode-back" href="../../../../generated/torchaudio.models.decoder.CTCDecoder.html#torchaudio.models.decoder.CTCDecoder.decode_step">[docs]</a>    <span class="k">def</span> <span class="nf">decode_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">emissions</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform incremental decoding on top of the curent internal state.</span>

<span class="sd">        .. note::</span>

<span class="sd">           This method is required only when performing online decoding.</span>
<span class="sd">           It is not necessary when performing batch decoding with :py:meth:`__call__`.</span>

<span class="sd">        Args:</span>
<span class="sd">            emissions (torch.FloatTensor): CPU tensor of shape `(frame, num_tokens)` storing sequences of</span>
<span class="sd">                probability distribution over labels; output of acoustic model.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; decoder = torchaudio.models.decoder.ctc_decoder(...)</span>
<span class="sd">            &gt;&gt;&gt; decoder.decode_begin()</span>
<span class="sd">            &gt;&gt;&gt; decoder.decode_step(emission1)</span>
<span class="sd">            &gt;&gt;&gt; decoder.decode_step(emission2)</span>
<span class="sd">            &gt;&gt;&gt; decoder.decode_end()</span>
<span class="sd">            &gt;&gt;&gt; result = decoder.get_final_hypothesis()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">emissions</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;emissions must be float32.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">emissions</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;emissions must be a CPU tensor.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">emissions</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;emissions must be contiguous.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">emissions</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;emissions must be 2D. Found </span><span class="si">{</span><span class="n">emissions</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">T</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="n">emissions</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">decode_step</span><span class="p">(</span><span class="n">emissions</span><span class="o">.</span><span class="n">data_ptr</span><span class="p">(),</span> <span class="n">T</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_to_hypo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">results</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">CTCHypothesis</span><span class="p">]:</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="n">CTCHypothesis</span><span class="p">(</span>
                <span class="n">tokens</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_tokens</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">tokens</span><span class="p">),</span>
                <span class="n">words</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">word_dict</span><span class="o">.</span><span class="n">get_entry</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">result</span><span class="o">.</span><span class="n">words</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">],</span>
                <span class="n">score</span><span class="o">=</span><span class="n">result</span><span class="o">.</span><span class="n">score</span><span class="p">,</span>
                <span class="n">timesteps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_timesteps</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">tokens</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span>
        <span class="p">]</span>

<div class="viewcode-block" id="CTCDecoder.get_final_hypothesis"><a class="viewcode-back" href="../../../../generated/torchaudio.models.decoder.CTCDecoder.html#torchaudio.models.decoder.CTCDecoder.get_final_hypothesis">[docs]</a>    <span class="k">def</span> <span class="nf">get_final_hypothesis</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">CTCHypothesis</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the final hypothesis</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[CTCHypothesis]:</span>
<span class="sd">                List of sorted best hypotheses.</span>

<span class="sd">        .. note::</span>

<span class="sd">           This method is required only when performing online decoding.</span>
<span class="sd">           It is not necessary when performing batch decoding with :py:meth:`__call__`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">get_all_final_hypothesis</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_hypo</span><span class="p">(</span><span class="n">results</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">nbest</span><span class="p">])</span></div>

<div class="viewcode-block" id="CTCDecoder.__call__"><a class="viewcode-back" href="../../../../generated/torchaudio.models.decoder.CTCDecoder.html#torchaudio.models.decoder.CTCDecoder.__call__">[docs]</a>    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">emissions</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">,</span> <span class="n">lengths</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">CTCHypothesis</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Performs batched offline decoding.</span>

<span class="sd">        .. note::</span>

<span class="sd">           This method performs offline decoding in one go. To perform incremental decoding,</span>
<span class="sd">           please refer to :py:meth:`decode_step`.</span>

<span class="sd">        Args:</span>
<span class="sd">            emissions (torch.FloatTensor): CPU tensor of shape `(batch, frame, num_tokens)` storing sequences of</span>
<span class="sd">                probability distribution over labels; output of acoustic model.</span>
<span class="sd">            lengths (Tensor or None, optional): CPU tensor of shape `(batch, )` storing the valid length of</span>
<span class="sd">                in time axis of the output Tensor in each batch.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[List[CTCHypothesis]]:</span>
<span class="sd">                List of sorted best hypotheses for each audio sequence in the batch.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">emissions</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;emissions must be float32.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">emissions</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;emissions must be a CPU tensor.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">emissions</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;emissions must be contiguous.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">emissions</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;emissions must be 3D. Found </span><span class="si">{</span><span class="n">emissions</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">lengths</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">lengths</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;lengths must be a CPU tensor.&quot;</span><span class="p">)</span>

        <span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="n">emissions</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">lengths</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">lengths</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">B</span><span class="p">,),</span> <span class="n">T</span><span class="p">)</span>

        <span class="n">float_bytes</span> <span class="o">=</span> <span class="mi">4</span>
        <span class="n">hypos</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
            <span class="n">emissions_ptr</span> <span class="o">=</span> <span class="n">emissions</span><span class="o">.</span><span class="n">data_ptr</span><span class="p">()</span> <span class="o">+</span> <span class="n">float_bytes</span> <span class="o">*</span> <span class="n">b</span> <span class="o">*</span> <span class="n">emissions</span><span class="o">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">emissions_ptr</span><span class="p">,</span> <span class="n">lengths</span><span class="p">[</span><span class="n">b</span><span class="p">],</span> <span class="n">N</span><span class="p">)</span>
            <span class="n">hypos</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_to_hypo</span><span class="p">(</span><span class="n">results</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">nbest</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">hypos</span></div>

<div class="viewcode-block" id="CTCDecoder.idxs_to_tokens"><a class="viewcode-back" href="../../../../generated/torchaudio.models.decoder.CTCDecoder.html#torchaudio.models.decoder.CTCDecoder.idxs_to_tokens">[docs]</a>    <span class="k">def</span> <span class="nf">idxs_to_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idxs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Map raw token IDs into corresponding tokens</span>

<span class="sd">        Args:</span>
<span class="sd">            idxs (LongTensor): raw token IDs generated from decoder</span>

<span class="sd">        Returns:</span>
<span class="sd">            List: tokens corresponding to the input IDs</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens_dict</span><span class="o">.</span><span class="n">get_entry</span><span class="p">(</span><span class="n">idx</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">idxs</span><span class="p">]</span></div></div>


<div class="viewcode-block" id="ctc_decoder"><a class="viewcode-back" href="../../../../generated/torchaudio.models.decoder.ctc_decoder.html#torchaudio.models.decoder.ctc_decoder">[docs]</a><span class="k">def</span> <span class="nf">ctc_decoder</span><span class="p">(</span>
    <span class="n">lexicon</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">tokens</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">lm</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">CTCDecoderLM</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">lm_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">nbest</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">beam_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
    <span class="n">beam_size_token</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">beam_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
    <span class="n">lm_weight</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">word_score</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">unk_score</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">),</span>
    <span class="n">sil_score</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">log_add</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">blank_token</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;-&quot;</span><span class="p">,</span>
    <span class="n">sil_token</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;|&quot;</span><span class="p">,</span>
    <span class="n">unk_word</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&lt;unk&gt;&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">CTCDecoder</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Builds an instance of :class:`CTCDecoder`.</span>

<span class="sd">    Args:</span>
<span class="sd">        lexicon (str or None): lexicon file containing the possible words and corresponding spellings.</span>
<span class="sd">            Each line consists of a word and its space separated spelling. If `None`, uses lexicon-free</span>
<span class="sd">            decoding.</span>
<span class="sd">        tokens (str or List[str]): file or list containing valid tokens. If using a file, the expected</span>
<span class="sd">            format is for tokens mapping to the same index to be on the same line</span>
<span class="sd">        lm (str, CTCDecoderLM, or None, optional): either a path containing KenLM language model,</span>
<span class="sd">            custom language model of type `CTCDecoderLM`, or `None` if not using a language model</span>
<span class="sd">        lm_dict (str or None, optional): file consisting of the dictionary used for the LM, with a word</span>
<span class="sd">            per line sorted by LM index. If decoding with a lexicon, entries in lm_dict must also occur</span>
<span class="sd">            in the lexicon file. If `None`, dictionary for LM is constructed using the lexicon file.</span>
<span class="sd">            (Default: None)</span>
<span class="sd">        nbest (int, optional): number of best decodings to return (Default: 1)</span>
<span class="sd">        beam_size (int, optional): max number of hypos to hold after each decode step (Default: 50)</span>
<span class="sd">        beam_size_token (int, optional): max number of tokens to consider at each decode step.</span>
<span class="sd">            If `None`, it is set to the total number of tokens (Default: None)</span>
<span class="sd">        beam_threshold (float, optional): threshold for pruning hypothesis (Default: 50)</span>
<span class="sd">        lm_weight (float, optional): weight of language model (Default: 2)</span>
<span class="sd">        word_score (float, optional): word insertion score (Default: 0)</span>
<span class="sd">        unk_score (float, optional): unknown word insertion score (Default: -inf)</span>
<span class="sd">        sil_score (float, optional): silence insertion score (Default: 0)</span>
<span class="sd">        log_add (bool, optional): whether or not to use logadd when merging hypotheses (Default: False)</span>
<span class="sd">        blank_token (str, optional): token corresponding to blank (Default: &quot;-&quot;)</span>
<span class="sd">        sil_token (str, optional): token corresponding to silence (Default: &quot;|&quot;)</span>
<span class="sd">        unk_word (str, optional): word corresponding to unknown (Default: &quot;&lt;unk&gt;&quot;)</span>

<span class="sd">    Returns:</span>
<span class="sd">        CTCDecoder: decoder</span>

<span class="sd">    Example</span>
<span class="sd">        &gt;&gt;&gt; decoder = ctc_decoder(</span>
<span class="sd">        &gt;&gt;&gt;     lexicon=&quot;lexicon.txt&quot;,</span>
<span class="sd">        &gt;&gt;&gt;     tokens=&quot;tokens.txt&quot;,</span>
<span class="sd">        &gt;&gt;&gt;     lm=&quot;kenlm.bin&quot;,</span>
<span class="sd">        &gt;&gt;&gt; )</span>
<span class="sd">        &gt;&gt;&gt; results = decoder(emissions) # List of shape (B, nbest) of Hypotheses</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">lm_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">type</span><span class="p">(</span><span class="n">lm_dict</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;lm_dict must be None or str type.&quot;</span><span class="p">)</span>

    <span class="n">tokens_dict</span> <span class="o">=</span> <span class="n">_Dictionary</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>

    <span class="c1"># decoder options</span>
    <span class="k">if</span> <span class="n">lexicon</span><span class="p">:</span>
        <span class="n">lexicon</span> <span class="o">=</span> <span class="n">_load_words</span><span class="p">(</span><span class="n">lexicon</span><span class="p">)</span>
        <span class="n">decoder_options</span> <span class="o">=</span> <span class="n">_LexiconDecoderOptions</span><span class="p">(</span>
            <span class="n">beam_size</span><span class="o">=</span><span class="n">beam_size</span><span class="p">,</span>
            <span class="n">beam_size_token</span><span class="o">=</span><span class="n">beam_size_token</span> <span class="ow">or</span> <span class="n">tokens_dict</span><span class="o">.</span><span class="n">index_size</span><span class="p">(),</span>
            <span class="n">beam_threshold</span><span class="o">=</span><span class="n">beam_threshold</span><span class="p">,</span>
            <span class="n">lm_weight</span><span class="o">=</span><span class="n">lm_weight</span><span class="p">,</span>
            <span class="n">word_score</span><span class="o">=</span><span class="n">word_score</span><span class="p">,</span>
            <span class="n">unk_score</span><span class="o">=</span><span class="n">unk_score</span><span class="p">,</span>
            <span class="n">sil_score</span><span class="o">=</span><span class="n">sil_score</span><span class="p">,</span>
            <span class="n">log_add</span><span class="o">=</span><span class="n">log_add</span><span class="p">,</span>
            <span class="n">criterion_type</span><span class="o">=</span><span class="n">_CriterionType</span><span class="o">.</span><span class="n">CTC</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">decoder_options</span> <span class="o">=</span> <span class="n">_LexiconFreeDecoderOptions</span><span class="p">(</span>
            <span class="n">beam_size</span><span class="o">=</span><span class="n">beam_size</span><span class="p">,</span>
            <span class="n">beam_size_token</span><span class="o">=</span><span class="n">beam_size_token</span> <span class="ow">or</span> <span class="n">tokens_dict</span><span class="o">.</span><span class="n">index_size</span><span class="p">(),</span>
            <span class="n">beam_threshold</span><span class="o">=</span><span class="n">beam_threshold</span><span class="p">,</span>
            <span class="n">lm_weight</span><span class="o">=</span><span class="n">lm_weight</span><span class="p">,</span>
            <span class="n">sil_score</span><span class="o">=</span><span class="n">sil_score</span><span class="p">,</span>
            <span class="n">log_add</span><span class="o">=</span><span class="n">log_add</span><span class="p">,</span>
            <span class="n">criterion_type</span><span class="o">=</span><span class="n">_CriterionType</span><span class="o">.</span><span class="n">CTC</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># construct word dict and language model</span>
    <span class="n">word_dict</span> <span class="o">=</span> <span class="n">_get_word_dict</span><span class="p">(</span><span class="n">lexicon</span><span class="p">,</span> <span class="n">lm</span><span class="p">,</span> <span class="n">lm_dict</span><span class="p">,</span> <span class="n">tokens_dict</span><span class="p">,</span> <span class="n">unk_word</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">lm</span><span class="p">)</span> <span class="o">==</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">_KenLM</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;flashlight-text is installed, but KenLM is not installed. &quot;</span>
                <span class="s2">&quot;Please refer to https://github.com/kpu/kenlm#python-module for how to install it.&quot;</span>
            <span class="p">)</span>
        <span class="n">lm</span> <span class="o">=</span> <span class="n">_KenLM</span><span class="p">(</span><span class="n">lm</span><span class="p">,</span> <span class="n">word_dict</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">lm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">lm</span> <span class="o">=</span> <span class="n">_ZeroLM</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">CTCDecoder</span><span class="p">(</span>
        <span class="n">nbest</span><span class="o">=</span><span class="n">nbest</span><span class="p">,</span>
        <span class="n">lexicon</span><span class="o">=</span><span class="n">lexicon</span><span class="p">,</span>
        <span class="n">word_dict</span><span class="o">=</span><span class="n">word_dict</span><span class="p">,</span>
        <span class="n">tokens_dict</span><span class="o">=</span><span class="n">tokens_dict</span><span class="p">,</span>
        <span class="n">lm</span><span class="o">=</span><span class="n">lm</span><span class="p">,</span>
        <span class="n">decoder_options</span><span class="o">=</span><span class="n">decoder_options</span><span class="p">,</span>
        <span class="n">blank_token</span><span class="o">=</span><span class="n">blank_token</span><span class="p">,</span>
        <span class="n">sil_token</span><span class="o">=</span><span class="n">sil_token</span><span class="p">,</span>
        <span class="n">unk_word</span><span class="o">=</span><span class="n">unk_word</span><span class="p">,</span>
    <span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_get_filenames</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_PretrainedFiles</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">model</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;librispeech&quot;</span><span class="p">,</span> <span class="s2">&quot;librispeech-3-gram&quot;</span><span class="p">,</span> <span class="s2">&quot;librispeech-4-gram&quot;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s2"> not supported. Must be one of [&#39;librispeech-3-gram&#39;, &#39;librispeech-4-gram&#39;, &#39;librispeech&#39;]&quot;</span>
        <span class="p">)</span>

    <span class="n">prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;decoder-assets/</span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">return</span> <span class="n">_PretrainedFiles</span><span class="p">(</span>
        <span class="n">lexicon</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">/lexicon.txt&quot;</span><span class="p">,</span>
        <span class="n">tokens</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">/tokens.txt&quot;</span><span class="p">,</span>
        <span class="n">lm</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">/lm.bin&quot;</span> <span class="k">if</span> <span class="n">model</span> <span class="o">!=</span> <span class="s2">&quot;librispeech&quot;</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span>


<div class="viewcode-block" id="download_pretrained_files"><a class="viewcode-back" href="../../../../generated/torchaudio.models.decoder.download_pretrained_files.html#torchaudio.models.decoder.download_pretrained_files">[docs]</a><span class="k">def</span> <span class="nf">download_pretrained_files</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_PretrainedFiles</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Retrieves pretrained data files used for :func:`ctc_decoder`.</span>

<span class="sd">    Args:</span>
<span class="sd">        model (str): pretrained language model to download.</span>
<span class="sd">            Valid values are: ``&quot;librispeech-3-gram&quot;``, ``&quot;librispeech-4-gram&quot;`` and ``&quot;librispeech&quot;``.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Object with the following attributes</span>

<span class="sd">            * ``lm``: path corresponding to downloaded language model,</span>
<span class="sd">              or ``None`` if the model is not associated with an lm</span>
<span class="sd">            * ``lexicon``: path corresponding to downloaded lexicon file</span>
<span class="sd">            * ``tokens``: path corresponding to downloaded tokens file</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">files</span> <span class="o">=</span> <span class="n">_get_filenames</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">lexicon_file</span> <span class="o">=</span> <span class="n">download_asset</span><span class="p">(</span><span class="n">files</span><span class="o">.</span><span class="n">lexicon</span><span class="p">)</span>
    <span class="n">tokens_file</span> <span class="o">=</span> <span class="n">download_asset</span><span class="p">(</span><span class="n">files</span><span class="o">.</span><span class="n">tokens</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">files</span><span class="o">.</span><span class="n">lm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">lm_file</span> <span class="o">=</span> <span class="n">download_asset</span><span class="p">(</span><span class="n">files</span><span class="o">.</span><span class="n">lm</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">lm_file</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">return</span> <span class="n">_PretrainedFiles</span><span class="p">(</span>
        <span class="n">lexicon</span><span class="o">=</span><span class="n">lexicon_file</span><span class="p">,</span>
        <span class="n">tokens</span><span class="o">=</span><span class="n">tokens_file</span><span class="p">,</span>
        <span class="n">lm</span><span class="o">=</span><span class="n">lm_file</span><span class="p">,</span>
    <span class="p">)</span></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2023, Torchaudio Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>


        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
         <script src="../../../../_static/jquery.js"></script>
         <script src="../../../../_static/underscore.js"></script>
         <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../../_static/doctools.js"></script>
         <script src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.js"></script>
         <script src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/contrib/auto-render.min.js"></script>
         <script src="../../../../_static/katex_autorenderer.js"></script>
     

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <script type="text/javascript">
    var collapsedSections = ['API Tutorials', 'Pipeline Tutorials', 'Training Recipes']
    </script>
     
    <script type="text/javascript">
      $(document).ready(function() {
	  var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
	  if (downloadNote.length >= 1) {
	      var tutorialUrl = $("#tutorial-type").text();
	      var githubLink = "https://github.com/pytorch/audio/blob/main/examples/"  + tutorialUrl + ".py",
		  notebookLink = $(".reference.download")[1].href,
		  notebookDownloadPath = notebookLink.split('_downloads')[1],
		  colabLink = "https://colab.research.google.com/github/pytorch/audio/blob/gh-pages/main/_downloads" + notebookDownloadPath;

	      $(".pytorch-call-to-action-links a[data-response='Run in Google Colab']").attr("href", colabLink);
	      $(".pytorch-call-to-action-links a[data-response='View on Github']").attr("href", githubLink);
	  }

          var overwrite = function(_) {
              if ($(this).length > 0) {
                  $(this)[0].href = "https://github.com/pytorch/audio"
              }
          }
          // PC
          $(".main-menu a:contains('GitHub')").each(overwrite);
          // Mobile
          $(".main-menu a:contains('Github')").each(overwrite);
      });

      
       $(window).ready(function() {
           var original = window.sideMenus.bind;
           var startup = true;
           window.sideMenus.bind = function() {
               original();
               if (startup) {
                   $("#pytorch-right-menu a.reference.internal").each(function(i) {
                       if (this.classList.contains("not-expanded")) {
                           this.nextElementSibling.style.display = "block";
                           this.classList.remove("not-expanded");
                           this.classList.add("expanded");
                       }
                   });
                   startup = false;
               }
           };
       });
    </script>

    


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>Â© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>
            
          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>
            
           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>