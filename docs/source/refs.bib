@article{wavernn,
  author    = {Nal Kalchbrenner and
               Erich Elsen and
               Karen Simonyan and
               Seb Noury and
               Norman Casagrande and
               Edward Lockhart and
               Florian Stimberg and
               A{\"{a}}ron van den Oord and
               Sander Dieleman and
               Koray Kavukcuoglu},
  title     = {Efficient Neural Audio Synthesis},
  journal   = {CoRR},
  volume    = {abs/1802.08435},
  year      = {2018},
  url       = {http://arxiv.org/abs/1802.08435},
  eprinttype = {arXiv},
  eprint    = {1802.08435},
  timestamp = {Mon, 13 Aug 2018 16:47:01 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1802-08435.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@misc{RESAMPLE,
	author = {Julius O. Smith},
	title = {Digital Audio Resampling Home Page "Theory of Ideal Bandlimited Interpolation" section},
	url = {https://ccrma.stanford.edu/~jos/resample/Theory_Ideal_Bandlimited_Interpolation.html},
	month = {September},
	year = {2020}
}
@article{voxpopuli,
  author    = {Changhan Wang and
               Morgane Rivi{\`{e}}re and
               Ann Lee and
               Anne Wu and
               Chaitanya Talnikar and
               Daniel Haziza and
               Mary Williamson and
               Juan Miguel Pino and
               Emmanuel Dupoux},
  title     = {VoxPopuli: {A} Large-Scale Multilingual Speech Corpus for Representation
               Learning, Semi-Supervised Learning and Interpretation},
  journal   = {CoRR},
  volume    = {abs/2101.00390},
  year      = {2021},
  url       = {https://arxiv.org/abs/2101.00390},
  eprinttype = {arXiv},
  eprint    = {2101.00390},
  timestamp = {Thu, 12 Aug 2021 15:37:06 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2101-00390.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{specaugment,
   title={SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition},
   url={http://dx.doi.org/10.21437/Interspeech.2019-2680},
   DOI={10.21437/interspeech.2019-2680},
   journal={Interspeech 2019},
   publisher={ISCA},
   author={Park, Daniel S. and Chan, William and Zhang, Yu and Chiu, Chung-Cheng and Zoph, Barret and Cubuk, Ekin D. and Le, Quoc V.},
   year={2019},
   month={Sep}
}
@misc{ljspeech17,
  author       = {Keith Ito and Linda Johnson},
  title        = {The LJ Speech Dataset},
  howpublished = {\url{https://keithito.com/LJ-Speech-Dataset/}},
  year         = {2017}
}
@misc{conneau2020unsupervised,
      title={Unsupervised Cross-lingual Representation Learning for Speech Recognition}, 
      author={Alexis Conneau and Alexei Baevski and Ronan Collobert and Abdelrahman Mohamed and Michael Auli},
      year={2020},
      eprint={2006.13979},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{Gales2014SpeechRA,
  title={Speech recognition and keyword spotting for low-resource languages: Babel project research at CUED},
  author={Mark John Francis Gales and Kate Knill and Anton Ragni and Shakti Prasad Rath},
  booktitle={SLTU},
  year={2014}
}
@misc{ardila2020common,
      title={Common Voice: A Massively-Multilingual Speech Corpus}, 
      author={Rosana Ardila and Megan Branson and Kelly Davis and Michael Henretty and Michael Kohler and Josh Meyer and Reuben Morais and Lindsay Saunders and Francis M. Tyers and Gregor Weber},
      year={2020},
      eprint={1912.06670},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{Pratap_2020,
   title={MLS: A Large-Scale Multilingual Dataset for Speech Research},
   url={http://dx.doi.org/10.21437/Interspeech.2020-2826},
   DOI={10.21437/interspeech.2020-2826},
   journal={Interspeech 2020},
   publisher={ISCA},
   author={Pratap, Vineel and Xu, Qiantong and Sriram, Anuroop and Synnaeve, Gabriel and Collobert, Ronan},
   year={2020},
   month={Oct}
}
@INPROCEEDINGS{librilight,
  author={J. {Kahn} and M. {Rivière} and W. {Zheng} and E. {Kharitonov} and Q. {Xu} and P. E. {Mazaré} and J. {Karadayi} and V. {Liptchinsky} and R. {Collobert} and C. {Fuegen} and T. {Likhomanenko} and G. {Synnaeve} and A. {Joulin} and A. {Mohamed} and E. {Dupoux}},
  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Libri-Light: A Benchmark for ASR with Limited or No Supervision}, 
  year={2020},
  pages={7669-7673},
  note = {\url{https://github.com/facebookresearch/libri-light}},
}
@INPROCEEDINGS{7178964,
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Librispeech: An ASR corpus based on public domain audio books}, 
  year={2015},
  volume={},
  number={},
  pages={5206-5210},
  doi={10.1109/ICASSP.2015.7178964}
}
@inproceedings{ott2019fairseq,
  title = {fairseq: A Fast, Extensible Toolkit for Sequence Modeling},
  author = {Myle Ott and Sergey Edunov and Alexei Baevski and Angela Fan and Sam Gross and Nathan Ng and David Grangier and Michael Auli},
  booktitle = {Proceedings of NAACL-HLT 2019: Demonstrations},
  year = {2019},
}
@misc{baevski2020wav2vec,
      title={wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations}, 
      author={Alexei Baevski and Henry Zhou and Abdelrahman Mohamed and Michael Auli},
      year={2020},
      eprint={2006.11477},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{hsu2021hubert,
      title={HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units}, 
      author={Wei-Ning Hsu and Benjamin Bolte and Yao-Hung Hubert Tsai and Kushal Lakhotia and Ruslan Salakhutdinov and Abdelrahman Mohamed},
      year={2021},
      eprint={2106.07447},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{hannun2014deep,
      title={Deep Speech: Scaling up end-to-end speech recognition}, 
      author={Awni Hannun and Carl Case and Jared Casper and Bryan Catanzaro and Greg Diamos and Erich Elsen and Ryan Prenger and Sanjeev Satheesh and Shubho Sengupta and Adam Coates and Andrew Y. Ng},
      year={2014},
      eprint={1412.5567},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{graves2012sequence,
      title={Sequence Transduction with Recurrent Neural Networks}, 
      author={Alex Graves},
      year={2012},
      eprint={1211.3711},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}
@misc{collobert2016wav2letter,
      title={Wav2Letter: an End-to-End ConvNet-based Speech Recognition System}, 
      author={Ronan Collobert and Christian Puhrsch and Gabriel Synnaeve},
      year={2016},
      eprint={1609.03193},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{kalchbrenner2018efficient,
      title={Efficient Neural Audio Synthesis}, 
      author={Nal Kalchbrenner and Erich Elsen and Karen Simonyan and Seb Noury and Norman Casagrande and Edward Lockhart and Florian Stimberg and Aaron van den Oord and Sander Dieleman and Koray Kavukcuoglu},
      year={2018},
      eprint={1802.08435},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}
@misc{gulati2020conformer,
      title={Conformer: Convolution-augmented Transformer for Speech Recognition},
      author={Anmol Gulati and James Qin and Chung-Cheng Chiu and Niki Parmar and Yu Zhang and Jiahui Yu and Wei Han and Shibo Wang and Zhengdong Zhang and Yonghui Wu and Ruoming Pang},
      year={2020},
      eprint={2005.08100},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}
@article{Luo_2019,
   title={Conv-TasNet: Surpassing Ideal Time–Frequency Magnitude Masking for Speech Separation},
   volume={27},
   ISSN={2329-9304},
   url={http://dx.doi.org/10.1109/TASLP.2019.2915167},
   DOI={10.1109/taslp.2019.2915167},
   number={8},
   journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Luo, Yi and Mesgarani, Nima},
   year={2019},
   month={Aug},
   pages={1256–1266}
}
@InProceedings{ brian_mcfee-proc-scipy-2015,
  author    = { {B}rian {M}c{F}ee and {C}olin {R}affel and {D}awen {L}iang and {D}aniel {P}.{W}. {E}llis and {M}att {M}c{V}icar and {E}ric {B}attenberg and {O}riol {N}ieto },
  title     = { librosa: {A}udio and {M}usic {S}ignal {A}nalysis in {P}ython },
  booktitle = { {P}roceedings of the 14th {P}ython in {S}cience {C}onference },
  pages     = { 18 - 24 },
  year      = { 2015 },
  editor    = { {K}athryn {H}uff and {J}ames {B}ergstra },
  doi       = { 10.25080/Majora-7b98e3ed-003 }
}
@INPROCEEDINGS{6701851,
  author={Perraudin, Nathanaël and Balazs, Peter and Søndergaard, Peter L.},
  booktitle={2013 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics}, 
  title={A fast Griffin-Lim algorithm}, 
  year={2013},
  volume={},
  number={},
  pages={1-4},
  doi={10.1109/WASPAA.2013.6701851}}
@INPROCEEDINGS{1172092,
  author={Griffin, D. and Jae Lim},
  booktitle={ICASSP '83. IEEE International Conference on Acoustics, Speech, and Signal Processing}, 
  title={Signal estimation from modified short-time Fourier transform}, 
  year={1983},
  volume={8},
  number={},
  pages={804-807},
  doi={10.1109/ICASSP.1983.1172092}}
@INPROCEEDINGS{6854049,
  author={Ghahremani, Pegah and BabaAli, Bagher and Povey, Daniel and Riedhammer, Korbinian and Trmal, Jan and Khudanpur, Sanjeev},
  booktitle={2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={A pitch extraction algorithm tuned for automatic speech recognition}, 
  year={2014},
  volume={},
  number={},
  pages={2494-2498},
  doi={10.1109/ICASSP.2014.6854049}}
@inproceedings{shen2018natural,
  title={Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions},
  author={Shen, Jonathan and Pang, Ruoming and Weiss, Ron J and Schuster, Mike and Jaitly, Navdeep and Yang, Zongheng and Chen, Zhifeng and Zhang, Yu and Wang, Yuxuan and Skerrv-Ryan, Rj and others},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={4779--4783},
  year={2018},
  organization={IEEE}
}
@inproceedings{souden2009optimal,
  title={On optimal frequency-domain multichannel linear filtering for noise reduction},
  author={Souden, Mehrez and Benesty, Jacob and Affes, Sofiene},
  booktitle={IEEE Transactions on audio, speech, and language processing},
  volume={18},
  number={2},
  pages={260--276},
  year={2009},
  publisher={IEEE}
}
@inproceedings{higuchi2016robust,
  title={Robust MVDR beamforming using time-frequency masks for online/offline ASR in noise},
  author={Higuchi, Takuya and Ito, Nobutaka and Yoshioka, Takuya and Nakatani, Tomohiro},
  booktitle={2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5210--5214},
  year={2016},
  organization={IEEE}
}
@inproceedings{shi2021emformer,
  title={Emformer: Efficient Memory Transformer Based Acoustic Model for Low Latency Streaming Speech Recognition}, 
  author={Shi, Yangyang and Wang, Yongqiang and Wu, Chunyang and Yeh, Ching-Feng and Chan, Julian and Zhang, Frank and Le, Duc and Seltzer, Mike},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  pages={6783-6787},
  year={2021}
}
@inproceedings{9747706,
  author={Shi, Yangyang and Wu, Chunyang and Wang, Dilin and Xiao, Alex and Mahadeokar, Jay and Zhang, Xiaohui and Liu, Chunxi and Li, Ke and Shangguan, Yuan and Nagaraja, Varun and Kalinli, Ozlem and Seltzer, Mike},
  booktitle={ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Streaming Transformer Transducer based Speech Recognition Using Non-Causal Convolution}, 
  year={2022},
  volume={},
  number={},
  pages={8277-8281},
  doi={10.1109/ICASSP43922.2022.9747706}}
@article{mises1929praktische,
  title={Praktische Verfahren der Gleichungsaufl{\"o}sung.},
  author={Mises, RV and Pollaczek-Geiringer, Hilda},
  journal={ZAMM-Journal of Applied Mathematics and Mechanics/Zeitschrift f{\"u}r Angewandte Mathematik und Mechanik},
  volume={9},
  number={1},
  pages={58--77},
  year={1929},
  publisher={Wiley Online Library}
}
@article{higuchi2017online,
  title={Online MVDR beamformer based on complex Gaussian mixture model with spatial prior for noise robust ASR},
  author={Higuchi, Takuya and Ito, Nobutaka and Araki, Shoko and Yoshioka, Takuya and Delcroix, Marc and Nakatani, Tomohiro},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={25},
  number={4},
  pages={780--793},
  year={2017},
  publisher={IEEE}
}
@article{capon1969high,
  title={High-resolution frequency-wavenumber spectrum analysis},
  author={Capon, Jack},
  journal={Proceedings of the IEEE},
  volume={57},
  number={8},
  pages={1408--1418},
  year={1969},
  publisher={IEEE}
}
@article{kahn2022flashlight,
  title={Flashlight: Enabling Innovation in Tools for Machine Learning},
  author={Kahn, Jacob and Pratap, Vineel and Likhomanenko, Tatiana and Xu, Qiantong and Hannun, Awni and Cai, Jeff and Tomasello, Paden and Lee, Ann and Grave, Edouard and Avidov, Gilad and others},
  journal={arXiv preprint arXiv:2201.12465},
  year={2022}
}
@TECHREPORT{Kominek03cmuarctic,
  author = {John Kominek and Alan W Black and Ver Ver},
  title = {CMU Arctic Databases for Speech Synthesis},
  institution = {},
  year = {2003}
}
@misc{cosentino2020librimix,
  title={LibriMix: An Open-Source Dataset for Generalizable Speech Separation},
  author={Joris Cosentino and Manuel Pariente and Samuele Cornell and Antoine Deleforge and Emmanuel Vincent},
  year={2020},
  eprint={2005.11262},
  archivePrefix={arXiv},
  primaryClass={eess.AS}
}
@article{Zen2019LibriTTSAC,
  title={LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech},
  author={Heiga Zen and Viet-Trung Dang and Robert A. J. Clark and Yu Zhang and Ron J. Weiss and Ye Jia and Z. Chen and Yonghui Wu},
  journal={ArXiv},
  year={2019},
  volume={abs/1904.02882}
}
@article{speechcommandsv2,
  author = { {Warden}, P.},
  title = "{Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition}",
  journal = {ArXiv e-prints},
  archivePrefix = "arXiv",
  eprint = {1804.03209},
  primaryClass = "cs.CL",
  keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},
  year = 2018,
  month = apr,
  url = {https://arxiv.org/abs/1804.03209},
}
@inproceedings{rousseau2012tedlium,
  title={TED-LIUM: an Automatic Speech Recognition dedicated corpus},
  author={Rousseau, Anthony and Del{\'e}glise, Paul and Est{\`e}ve, Yannick},
  booktitle={Conference on Language Resources and Evaluation (LREC)},
  pages={125--129},
  year={2012}
}
@misc{yamagishi2019vctk,
  author={Yamagishi, Junichi and Veaux, Christophe and MacDonald, Kirsten},
  title={ {CSTR VCTK Corpus}: English Multi-speaker Corpus for {CSTR} Voice Cloning Toolkit (version 0.92)},
  publisher={University of Edinburgh. The Centre for Speech Technology Research (CSTR)},
  year=2019,
  doi={10.7488/ds/2645},
}
@misc{Sarfjoo2018DeviceRV,
  title={Device Recorded VCTK (Small subset version)},
  author={Seyyed Saeed Sarfjoo and Junichi Yamagishi},
  year={2018}
}
@misc{tzanetakis_essl_cook_2001,
  author    = "Tzanetakis, George and Essl, Georg and Cook, Perry",
  title     = "Automatic Musical Genre Classification Of Audio Signals",
  url       = "http://ismir2001.ismir.net/pdf/tzanetakis.pdf",
  publisher = "The International Society for Music Information Retrieval",
  year      = "2001"
}
@article{Mir2015QUESST2014EQ,
  title={QUESST2014: Evaluating Query-by-Example Speech Search in a zero-resource setting with real-life queries},
  author={Xavier Anguera Miro and Luis Javier Rodriguez-Fuentes and Andi Buzo and Florian Metze and Igor Szoke and Mikel Pe{\~n}agarikano},
  journal={2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year={2015},
  pages={5833-5837}
}
@misc{cmudict,
  title={The Carnegie Mellon pronuncing dictionary},
  author={Weide, R.L.},
  year={1998},
  url={http://www.speech.cs.cmu.edu/cgi-bin/cmudict},
}
@misc{YesNo,
  title="YesNo",
  url="http://www.openslr.org/1/"
}
@misc{MUSDB18HQ,
  author       = {Rafii, Zafar and Liutkus, Antoine and Fabian-Robert St{\"o}ter and Mimilakis, Stylianos Ioannis and
                  Bittner, Rachel},
  title        = {{MUSDB18-HQ} - an uncompressed version of MUSDB18},
  month        = dec,
  year         = 2019,
  doi          = {10.5281/zenodo.3338373},
  url          = {https://doi.org/10.5281/zenodo.3338373}
}
@inproceedings{fluent,
  author    = {Loren Lugosch and Mirco Ravanelli and Patrick Ignoto and Vikrant Singh Tomar and Yoshua Bengio},
  editor    = {Gernot Kubin and Zdravko Kacic},
  title     = {Speech Model Pre-Training for End-to-End Spoken Language Understanding},
  booktitle = {Proc. of Interspeech},
  pages     = {814--818},
  year      = {2019},
}
@article{nagrani2017voxceleb,
  title={Voxceleb: a large-scale speaker identification dataset},
  author={Nagrani, Arsha and Chung, Joon Son and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1706.08612},
  year={2017}
}
@inproceedings{defossez2021hybrid,
  title={Hybrid Spectrogram and Waveform Source Separation},
  author={D{\'e}fossez, Alexandre},
  booktitle={Proceedings of the ISMIR 2021 Workshop on Music Source Separation},
  year={2021}
}
@article{CATTONI2021101155,
title = {MuST-C: A multilingual corpus for end-to-end speech translation},
journal = {Computer Speech & Language},
volume = {66},
pages = {101155},
year = {2021},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2020.101155},
url = {https://www.sciencedirect.com/science/article/pii/S0885230820300887},
author = {Roldano Cattoni and Mattia Antonino {Di Gangi} and Luisa Bentivogli and Matteo Negri and Marco Turchi},
keywords = {Spoken language translation, Multilingual corpus},
abstract = {End-to-end spoken language translation (SLT) has recently gained popularity thanks to the advancement of sequence to sequence learning in its two parent tasks: automatic speech recognition (ASR) and machine translation (MT). However, research in the field has to confront with the scarcity of publicly available corpora to train data-hungry neural networks. Indeed, while traditional cascade solutions can build on sizable ASR and MT training data for a variety of languages, the available SLT corpora suitable for end-to-end training are few, typically small and of limited language coverage. We contribute to fill this gap by presenting MuST-C, a large and freely available Multilingual Speech Translation Corpus built from English TED Talks. Its unique features include: i) language coverage and diversity (from English into 14 languages from different families), ii) size (at least 237 hours of transcribed recordings per language, 430 on average), iii) variety of topics and speakers, and iv) data quality. Besides describing the corpus creation methodology and discussing the outcomes of empirical and manual quality evaluations, we present baseline results computed with strong systems on each language direction covered by MuST-C.}
}
