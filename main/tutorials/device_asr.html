


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Device ASR with Emformer RNN-T &mdash; Torchaudio nightly documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Forced Alignment with Wav2Vec2" href="forced_alignment_tutorial.html" />
    <link rel="prev" title="Online ASR with Emformer RNN-T" href="online_asr_tutorial.html" />
  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117752657-2');
    </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorch’s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href="../../versions.html">Nightly Build (0.14.0.dev20221106) &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Torchaudio Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Index</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supported_features.html">Supported Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../feature_classifications.html">Feature Classifications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html">References</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="audio_io_tutorial.html">Audio I/O</a></li>
<li class="toctree-l1"><a class="reference internal" href="streamreader_basic_tutorial.html">StreamReader Basic Usages</a></li>
<li class="toctree-l1"><a class="reference internal" href="streamreader_advanced_tutorial.html">StreamReader Advanced Usages</a></li>
<li class="toctree-l1"><a class="reference internal" href="streamwriter_basic_tutorial.html">StreamWriter Basic Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="streamwriter_advanced.html">StreamWriter Advanced Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hw_acceleration_tutorial.html">Hardware-Accelerated Video Decoding and Encoding</a></li>
<li class="toctree-l1"><a class="reference internal" href="audio_resampling_tutorial.html">Audio Resampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="audio_data_augmentation_tutorial.html">Audio Data Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="audio_feature_extractions_tutorial.html">Audio Feature Extractions</a></li>
<li class="toctree-l1"><a class="reference internal" href="audio_feature_augmentation_tutorial.html">Audio Feature Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="audio_datasets_tutorial.html">Audio Datasets</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Pipeline Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="speech_recognition_pipeline_tutorial.html">Speech Recognition with Wav2Vec2</a></li>
<li class="toctree-l1"><a class="reference internal" href="asr_inference_with_ctc_decoder_tutorial.html">ASR Inference with CTC Decoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="online_asr_tutorial.html">Online ASR with Emformer RNN-T</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Device ASR with Emformer RNN-T</a></li>
<li class="toctree-l1"><a class="reference internal" href="forced_alignment_tutorial.html">Forced Alignment with Wav2Vec2</a></li>
<li class="toctree-l1"><a class="reference internal" href="tacotron2_pipeline_tutorial.html">Text-to-Speech with Tacotron2</a></li>
<li class="toctree-l1"><a class="reference internal" href="mvdr_tutorial.html">Speech Enhancement with MVDR Beamforming</a></li>
<li class="toctree-l1"><a class="reference internal" href="hybrid_demucs_tutorial.html">Music Source Separation with Hybrid Demucs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Training Recipes</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/pytorch/audio/tree/main/examples/asr/librispeech_conformer_rnnt">Conformer RNN-T ASR</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/pytorch/audio/tree/main/examples/asr/emformer_rnnt">Emformer RNN-T ASR</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/pytorch/audio/tree/main/examples/source_separation">Conv-TasNet Source Separation</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/pytorch/audio/tree/main/examples/hubert">HuBERT Pre-training and Fine-tuning (ASR)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../torchaudio.html">torchaudio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../io.html">torchaudio.io</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend.html">torchaudio.backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional.html">torchaudio.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../transforms.html">torchaudio.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets.html">torchaudio.datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models.html">torchaudio.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models.decoder.html">torchaudio.models.decoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pipelines.html">torchaudio.pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sox_effects.html">torchaudio.sox_effects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../compliance.kaldi.html">torchaudio.compliance.kaldi</a></li>
<li class="toctree-l1"><a class="reference internal" href="../kaldi_io.html">torchaudio.kaldi_io</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils.html">torchaudio.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Prototype API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../prototype.html">torchaudio.prototype</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prototype.functional.html">torchaudio.prototype.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prototype.models.html">torchaudio.prototype.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prototype.pipelines.html">torchaudio.prototype.pipelines</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PyTorch Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/docs">PyTorch</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/elastic/">TorchElastic</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="http://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Device ASR with Emformer RNN-T</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/tutorials/device_asr.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
    

    <div class="pytorch-call-to-action-links">
      <div id="tutorial-type">tutorials/device_asr</div>

      <div id="google-colab-link">
        <img class="call-to-action-img" src="../_static/images/pytorch-colab.svg"/>
        <div class="call-to-action-desktop-view">Run in Google Colab</div>
        <div class="call-to-action-mobile-view">Colab</div>
      </div>
      <div id="download-notebook-link">
        <img class="call-to-action-notebook-img" src="../_static/images/pytorch-download.svg"/>
        <div class="call-to-action-desktop-view">Download Notebook</div>
        <div class="call-to-action-mobile-view">Notebook</div>
      </div>
      <div id="github-view-link">
        <img class="call-to-action-img" src="../_static/images/pytorch-github.svg"/>
        <div class="call-to-action-desktop-view">View on GitHub</div>
        <div class="call-to-action-mobile-view">GitHub</div>
      </div>
    </div>

    
    
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-tutorials-device-asr-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="device-asr-with-emformer-rnn-t">
<span id="sphx-glr-tutorials-device-asr-py"></span><h1>Device ASR with Emformer RNN-T<a class="headerlink" href="#device-asr-with-emformer-rnn-t" title="Permalink to this heading">¶</a></h1>
<p><strong>Author</strong>: <a class="reference external" href="mailto:moto&#37;&#52;&#48;meta&#46;com">Moto Hira</a>, <a class="reference external" href="mailto:jeffhwang&#37;&#52;&#48;meta&#46;com">Jeff Hwang</a>.</p>
<p>This tutorial shows how to use Emformer RNN-T and streaming API
to perform speech recognition on a streaming device input, i.e. microphone
on laptop.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This tutorial requires FFmpeg libraries (&gt;=4.1, &lt;4.4) and SentencePiece.</p>
<p>There are multiple ways to install FFmpeg libraries.
If you are using Anaconda Python distribution,
<code class="docutils literal notranslate"><span class="pre">conda</span> <span class="pre">install</span> <span class="pre">'ffmpeg&lt;4.4'</span></code> will install
the required FFmpeg libraries.</p>
<p>You can install SentencePiece by running <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">sentencepiece</span></code>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This tutorial was tested on MacBook Pro and Dynabook with Windows 10.</p>
<p>This tutorial does NOT work on Google Colab because the server running
this tutorial does not have a microphone that you can talk to.</p>
</div>
<section id="overview">
<h2>1. Overview<a class="headerlink" href="#overview" title="Permalink to this heading">¶</a></h2>
<p>We use streaming API to fetch audio from audio device (microphone)
chunk by chunk, then run inference using Emformer RNN-T.</p>
<p>For the basic usage of the streaming API and Emformer RNN-T
please refer to
<a class="reference external" href="./streamreader_basic_tutorial.html">StreamReader Basic Usage</a> and
<a class="reference external" href="./online_asr_tutorial.html">Online ASR with Emformer RNN-T</a>.</p>
</section>
<section id="checking-the-supported-devices">
<h2>2. Checking the supported devices<a class="headerlink" href="#checking-the-supported-devices" title="Permalink to this heading">¶</a></h2>
<p>Firstly, we need to check the devices that Streaming API can access,
and figure out the arguments (<code class="docutils literal notranslate"><span class="pre">src</span></code> and <code class="docutils literal notranslate"><span class="pre">format</span></code>) we need to pass
to <a class="reference internal" href="../generated/torchaudio.io.StreamReader.html#torchaudio.io.StreamReader" title="torchaudio.io.StreamReader"><code class="xref py py-func docutils literal notranslate"><span class="pre">StreamReader()</span></code></a> class.</p>
<p>We use <code class="docutils literal notranslate"><span class="pre">ffmpeg</span></code> command for this. <code class="docutils literal notranslate"><span class="pre">ffmpeg</span></code> abstracts away the
difference of underlying hardware implementations, but the expected
value for <code class="docutils literal notranslate"><span class="pre">format</span></code> varies across OS and each <code class="docutils literal notranslate"><span class="pre">format</span></code> defines
different syntax for <code class="docutils literal notranslate"><span class="pre">src</span></code>.</p>
<p>The details of supported <code class="docutils literal notranslate"><span class="pre">format</span></code> values and <code class="docutils literal notranslate"><span class="pre">src</span></code> syntax can
be found in <a class="reference external" href="https://ffmpeg.org/ffmpeg-devices.html">https://ffmpeg.org/ffmpeg-devices.html</a>.</p>
<p>For macOS, the following command will list the available devices.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ffmpeg -f avfoundation -list_devices true -i dummy
...
[AVFoundation indev @ 0x126e049d0] AVFoundation video devices:
[AVFoundation indev @ 0x126e049d0] [0] FaceTime HD Camera
[AVFoundation indev @ 0x126e049d0] [1] Capture screen 0
[AVFoundation indev @ 0x126e049d0] AVFoundation audio devices:
[AVFoundation indev @ 0x126e049d0] [0] ZoomAudioDevice
[AVFoundation indev @ 0x126e049d0] [1] MacBook Pro Microphone
</pre></div>
</div>
<p>We will use the following values for Streaming API.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">StreamReader</span><span class="p">(</span>
    <span class="n">src</span> <span class="o">=</span> <span class="s2">&quot;:1&quot;</span><span class="p">,</span>  <span class="c1"># no video, audio from device 1, &quot;MacBook Pro Microphone&quot;</span>
    <span class="nb">format</span> <span class="o">=</span> <span class="s2">&quot;avfoundation&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>For Windows, <code class="docutils literal notranslate"><span class="pre">dshow</span></code> device should work.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="n">ffmpeg</span> <span class="o">-</span><span class="n">f</span> <span class="n">dshow</span> <span class="o">-</span><span class="n">list_devices</span> <span class="n">true</span> <span class="o">-</span><span class="n">i</span> <span class="n">dummy</span>
<span class="o">...</span>
<span class="p">[</span><span class="n">dshow</span> <span class="o">@</span> <span class="mi">000001</span><span class="n">adcabb02c0</span><span class="p">]</span> <span class="n">DirectShow</span> <span class="n">video</span> <span class="n">devices</span> <span class="p">(</span><span class="n">some</span> <span class="n">may</span> <span class="n">be</span> <span class="n">both</span> <span class="n">video</span> <span class="ow">and</span> <span class="n">audio</span> <span class="n">devices</span><span class="p">)</span>
<span class="p">[</span><span class="n">dshow</span> <span class="o">@</span> <span class="mi">000001</span><span class="n">adcabb02c0</span><span class="p">]</span>  <span class="s2">&quot;TOSHIBA Web Camera - FHD&quot;</span>
<span class="p">[</span><span class="n">dshow</span> <span class="o">@</span> <span class="mi">000001</span><span class="n">adcabb02c0</span><span class="p">]</span>     <span class="n">Alternative</span> <span class="n">name</span> <span class="s2">&quot;@device_pnp_</span><span class="se">\\</span><span class="s2">?\usb#vid_10f1&amp;pid_1a42&amp;mi_00#7&amp;27d916e6&amp;0&amp;0000#{65e8773d-8f56-11d0-a3b9-00a0c9223196}\global&quot;</span>
<span class="p">[</span><span class="n">dshow</span> <span class="o">@</span> <span class="mi">000001</span><span class="n">adcabb02c0</span><span class="p">]</span> <span class="n">DirectShow</span> <span class="n">audio</span> <span class="n">devices</span>
<span class="p">[</span><span class="n">dshow</span> <span class="o">@</span> <span class="mi">000001</span><span class="n">adcabb02c0</span><span class="p">]</span>  <span class="s2">&quot;... (Realtek High Definition Audio)&quot;</span>
<span class="p">[</span><span class="n">dshow</span> <span class="o">@</span> <span class="mi">000001</span><span class="n">adcabb02c0</span><span class="p">]</span>     <span class="n">Alternative</span> <span class="n">name</span> <span class="s2">&quot;@device_cm_{33D9A762-90C8-11D0-BD43-00A0C911CE86}\wave_{BF2B8AE1-10B8-4CA4-A0DC-D02E18A56177}&quot;</span>
</pre></div>
</div>
<p>In the above case, the following value can be used to stream from microphone.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">StreamReader</span><span class="p">(</span>
    <span class="n">src</span> <span class="o">=</span> <span class="s2">&quot;audio=@device_cm_{33D9A762-90C8-11D0-BD43-00A0C911CE86}\wave_{BF2B8AE1-10B8-4CA4-A0DC-D02E18A56177}&quot;</span><span class="p">,</span>
    <span class="nb">format</span> <span class="o">=</span> <span class="s2">&quot;dshow&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="data-acquisition">
<h2>3. Data acquisition<a class="headerlink" href="#data-acquisition" title="Permalink to this heading">¶</a></h2>
<p>Streaming audio from microphone input requires properly timing data
acquisition. Failing to do so may introduce discontinuities in the
data stream.</p>
<p>For this reason, we will run the data acquisition in a subprocess.</p>
<p>Firstly, we create a helper function that encapsulates the whole
process executed in the subprocess.</p>
<p>This function initializes the streaming API, acquires data then
puts it in a queue, which the main process is watching.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchaudio</span>


<span class="c1"># The data acquisition process will stop after this number of steps.</span>
<span class="c1"># This eliminates the need of process synchronization and makes this</span>
<span class="c1"># tutorial simple.</span>
<span class="n">NUM_ITER</span> <span class="o">=</span> <span class="mi">100</span>


<span class="k">def</span> <span class="nf">stream</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="nb">format</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">segment_length</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">torchaudio.io</span> <span class="kn">import</span> <span class="n">StreamReader</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Building StreamReader...&quot;</span><span class="p">)</span>
    <span class="n">streamer</span> <span class="o">=</span> <span class="n">StreamReader</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="nb">format</span><span class="p">)</span>
    <span class="n">streamer</span><span class="o">.</span><span class="n">add_basic_audio_stream</span><span class="p">(</span><span class="n">frames_per_chunk</span><span class="o">=</span><span class="n">segment_length</span><span class="p">,</span> <span class="n">sample_rate</span><span class="o">=</span><span class="n">sample_rate</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">streamer</span><span class="o">.</span><span class="n">get_src_stream_info</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">streamer</span><span class="o">.</span><span class="n">get_out_stream_info</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Streaming...&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="n">stream_iterator</span> <span class="o">=</span> <span class="n">streamer</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="n">timeout</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">backoff</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_ITER</span><span class="p">):</span>
        <span class="p">(</span><span class="n">chunk</span><span class="p">,)</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">stream_iterator</span><span class="p">)</span>
        <span class="n">q</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</pre></div>
</div>
<p>The notable difference from the non-device streaming is that,
we provide <code class="docutils literal notranslate"><span class="pre">timeout</span></code> and <code class="docutils literal notranslate"><span class="pre">backoff</span></code> parameters to <code class="docutils literal notranslate"><span class="pre">stream</span></code> method.</p>
<p>When acquiring data, if the rate of acquisition requests is higher
than that at which the hardware can prepare the data, then
the underlying implementation reports special error code, and expects
client code to retry.</p>
<p>Precise timing is the key for smooth streaming. Reporting this error
from low-level implementation all the way back to Python layer,
before retrying adds undesired overhead.
For this reason, the retry behavior is implemented in C++ layer, and
<code class="docutils literal notranslate"><span class="pre">timeout</span></code> and <code class="docutils literal notranslate"><span class="pre">backoff</span></code> parameters allow client code to control the
behavior.</p>
<p>For the detail of <code class="docutils literal notranslate"><span class="pre">timeout</span></code> and <code class="docutils literal notranslate"><span class="pre">backoff</span></code> parameters, please refer
to the documentation of
<a class="reference internal" href="../generated/torchaudio.io.StreamReader.html#torchaudio.io.StreamReader.stream" title="torchaudio.io.StreamReader.stream"><code class="xref py py-meth docutils literal notranslate"><span class="pre">stream()</span></code></a> method.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The proper value of <code class="docutils literal notranslate"><span class="pre">backoff</span></code> depends on the system configuration.
One way to see if <code class="docutils literal notranslate"><span class="pre">backoff</span></code> value is appropriate is to save the
series of acquired chunks as a continuous audio and listen to it.
If <code class="docutils literal notranslate"><span class="pre">backoff</span></code> value is too large, then the data stream is discontinuous.
The resulting audio sounds sped up.
If <code class="docutils literal notranslate"><span class="pre">backoff</span></code> value is too small or zero, the audio stream is fine,
but the data acquisition process enters busy-waiting state, and
this increases the CPU consumption.</p>
</div>
</section>
<section id="building-inference-pipeline">
<h2>4. Building inference pipeline<a class="headerlink" href="#building-inference-pipeline" title="Permalink to this heading">¶</a></h2>
<p>The next step is to create components required for inference.</p>
<p>This is the same process as
<a class="reference external" href="./online_asr_tutorial.html">Online ASR with Emformer RNN-T</a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Pipeline</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Build inference pipeline from RNNTBundle.</span>

<span class="sd">    Args:</span>
<span class="sd">        bundle (torchaudio.pipelines.RNNTBundle): Bundle object</span>
<span class="sd">        beam_width (int): Beam size of beam search decoder.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bundle</span><span class="p">:</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">pipelines</span><span class="o">.</span><span class="n">RNNTBundle</span><span class="p">,</span> <span class="n">beam_width</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bundle</span> <span class="o">=</span> <span class="n">bundle</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_extractor</span> <span class="o">=</span> <span class="n">bundle</span><span class="o">.</span><span class="n">get_streaming_feature_extractor</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">bundle</span><span class="o">.</span><span class="n">get_decoder</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_processor</span> <span class="o">=</span> <span class="n">bundle</span><span class="o">.</span><span class="n">get_token_processor</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">beam_width</span> <span class="o">=</span> <span class="n">beam_width</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hypothesis</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">infer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">segment</span><span class="p">:</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Perform streaming inference&quot;&quot;&quot;</span>
        <span class="n">features</span><span class="p">,</span> <span class="n">length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_extractor</span><span class="p">(</span><span class="n">segment</span><span class="p">)</span>
        <span class="n">hypos</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span>
            <span class="n">features</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beam_width</span><span class="p">,</span> <span class="n">state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="n">hypothesis</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hypothesis</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hypothesis</span> <span class="o">=</span> <span class="n">hypos</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">transcript</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_processor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hypothesis</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">transcript</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ContextCacher</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Cache the end of input data and prepend the next input data with it.</span>

<span class="sd">    Args:</span>
<span class="sd">        segment_length (int): The size of main segment.</span>
<span class="sd">            If the incoming segment is shorter, then the segment is padded.</span>
<span class="sd">        context_length (int): The size of the context, cached and appended.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">segment_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">context_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">segment_length</span> <span class="o">=</span> <span class="n">segment_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">context_length</span> <span class="o">=</span> <span class="n">context_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">context</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros" title="torch.zeros" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><span class="n">context_length</span><span class="p">])</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">chunk</span><span class="p">:</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></a><span class="p">):</span>
        <span class="k">if</span> <span class="n">chunk</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">segment_length</span><span class="p">:</span>
            <span class="n">chunk</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html#torch.nn.functional.pad" title="torch.nn.functional.pad" class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pad</span></a><span class="p">(</span><span class="n">chunk</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">segment_length</span> <span class="o">-</span> <span class="n">chunk</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)))</span>
        <span class="n">chunk_with_context</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.cat.html#torch.cat" title="torch.cat" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cat</span></a><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">chunk</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">context</span> <span class="o">=</span> <span class="n">chunk</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">context_length</span> <span class="p">:]</span>
        <span class="k">return</span> <span class="n">chunk_with_context</span>
</pre></div>
</div>
</section>
<section id="the-main-process">
<h2>5. The main process<a class="headerlink" href="#the-main-process" title="Permalink to this heading">¶</a></h2>
<p>The execution flow of the main process is as follows:</p>
<ol class="arabic simple">
<li><p>Initialize the inference pipeline.</p></li>
<li><p>Launch data acquisition subprocess.</p></li>
<li><p>Run inference.</p></li>
<li><p>Clean up</p></li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As the data acquisition subprocess will be launched with <cite>“spawn”</cite>
method, all the code on global scope are executed on the subprocess
as well.</p>
<p>We want to instantiate pipeline only in the main process,
so we put them in a function and invoke it within
<cite>__name__ == “__main__”</cite> guard.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">bundle</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">torchaudio</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Building pipeline...&quot;</span><span class="p">)</span>
    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">bundle</span><span class="p">)</span>

    <span class="n">sample_rate</span> <span class="o">=</span> <span class="n">bundle</span><span class="o">.</span><span class="n">sample_rate</span>
    <span class="n">segment_length</span> <span class="o">=</span> <span class="n">bundle</span><span class="o">.</span><span class="n">segment_length</span> <span class="o">*</span> <span class="n">bundle</span><span class="o">.</span><span class="n">hop_length</span>
    <span class="n">context_length</span> <span class="o">=</span> <span class="n">bundle</span><span class="o">.</span><span class="n">right_context_length</span> <span class="o">*</span> <span class="n">bundle</span><span class="o">.</span><span class="n">hop_length</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample rate: </span><span class="si">{</span><span class="n">sample_rate</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Main segment: </span><span class="si">{</span><span class="n">segment_length</span><span class="si">}</span><span class="s2"> frames (</span><span class="si">{</span><span class="n">segment_length</span> <span class="o">/</span> <span class="n">sample_rate</span><span class="si">}</span><span class="s2"> seconds)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Right context: </span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s2"> frames (</span><span class="si">{</span><span class="n">context_length</span> <span class="o">/</span> <span class="n">sample_rate</span><span class="si">}</span><span class="s2"> seconds)&quot;</span><span class="p">)</span>

    <span class="n">cacher</span> <span class="o">=</span> <span class="n">ContextCacher</span><span class="p">(</span><span class="n">segment_length</span><span class="p">,</span> <span class="n">context_length</span><span class="p">)</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">infer</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_ITER</span><span class="p">):</span>
            <span class="n">chunk</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
            <span class="n">segment</span> <span class="o">=</span> <span class="n">cacher</span><span class="p">(</span><span class="n">chunk</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
            <span class="n">transcript</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">segment</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">transcript</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="kn">import</span> <span class="nn">torch.multiprocessing</span> <span class="k">as</span> <span class="nn">mp</span>

    <span class="n">ctx</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">get_context</span><span class="p">(</span><span class="s2">&quot;spawn&quot;</span><span class="p">)</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">Process</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">stream</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">segment_length</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">))</span>
    <span class="n">p</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
    <span class="n">infer</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">(</span>
        <span class="n">device</span><span class="o">=</span><span class="s2">&quot;avfoundation&quot;</span><span class="p">,</span>
        <span class="n">src</span><span class="o">=</span><span class="s2">&quot;:1&quot;</span><span class="p">,</span>
        <span class="n">bundle</span><span class="o">=</span><span class="n">torchaudio</span><span class="o">.</span><span class="n">pipelines</span><span class="o">.</span><span class="n">EMFORMER_RNNT_BASE_LIBRISPEECH</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Building</span> <span class="n">pipeline</span><span class="o">...</span>
<span class="n">Sample</span> <span class="n">rate</span><span class="p">:</span> <span class="mi">16000</span>
<span class="n">Main</span> <span class="n">segment</span><span class="p">:</span> <span class="mi">2560</span> <span class="n">frames</span> <span class="p">(</span><span class="mf">0.16</span> <span class="n">seconds</span><span class="p">)</span>
<span class="n">Right</span> <span class="n">context</span><span class="p">:</span> <span class="mi">640</span> <span class="n">frames</span> <span class="p">(</span><span class="mf">0.04</span> <span class="n">seconds</span><span class="p">)</span>
<span class="n">Building</span> <span class="n">StreamReader</span><span class="o">...</span>
<span class="n">SourceAudioStream</span><span class="p">(</span><span class="n">media_type</span><span class="o">=</span><span class="s1">&#39;audio&#39;</span><span class="p">,</span> <span class="n">codec</span><span class="o">=</span><span class="s1">&#39;pcm_f32le&#39;</span><span class="p">,</span> <span class="n">codec_long_name</span><span class="o">=</span><span class="s1">&#39;PCM 32-bit floating point little-endian&#39;</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;flt&#39;</span><span class="p">,</span> <span class="n">bit_rate</span><span class="o">=</span><span class="mi">1536000</span><span class="p">,</span> <span class="n">sample_rate</span><span class="o">=</span><span class="mf">48000.0</span><span class="p">,</span> <span class="n">num_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">OutputStream</span><span class="p">(</span><span class="n">source_index</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">filter_description</span><span class="o">=</span><span class="s1">&#39;aresample=16000,aformat=sample_fmts=fltp&#39;</span><span class="p">)</span>
<span class="n">Streaming</span><span class="o">...</span>

<span class="n">hello</span> <span class="n">world</span>
</pre></div>
</div>
<p>Tag: <a class="reference internal" href="../io.html#module-torchaudio.io" title="torchaudio.io"><code class="xref py py-obj docutils literal notranslate"><span class="pre">torchaudio.io</span></code></a></p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  0.000 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-tutorials-device-asr-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/8009eae2a3a1a322f175ecc138597775/device_asr.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">device_asr.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c8265c298ed19ff44b504d5c3aa72563/device_asr.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">device_asr.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="forced_alignment_tutorial.html" class="btn btn-neutral float-right" title="Forced Alignment with Wav2Vec2" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="online_asr_tutorial.html" class="btn btn-neutral" title="Online ASR with Emformer RNN-T" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Torchaudio Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>


        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Device ASR with Emformer RNN-T</a><ul>
<li><a class="reference internal" href="#overview">1. Overview</a></li>
<li><a class="reference internal" href="#checking-the-supported-devices">2. Checking the supported devices</a></li>
<li><a class="reference internal" href="#data-acquisition">3. Data acquisition</a></li>
<li><a class="reference internal" href="#building-inference-pipeline">4. Building inference pipeline</a></li>
<li><a class="reference internal" href="#the-main-process">5. The main process</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.js"></script>
         <script src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/contrib/auto-render.min.js"></script>
         <script src="../_static/katex_autorenderer.js"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <script type="text/javascript">
    var collapsedSections = ['API Tutorials', 'Pipeline Tutorials', 'Training Recipes']
    </script>
     
    <script type="text/javascript">
      $(document).ready(function() {
	  var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
	  if (downloadNote.length >= 1) {
	      var tutorialUrl = $("#tutorial-type").text();
	      var githubLink = "https://github.com/pytorch/audio/blob/main/examples/"  + tutorialUrl + ".py",
		  notebookLink = $(".reference.download")[1].href,
		  notebookDownloadPath = notebookLink.split('_downloads')[1],
		  colabLink = "https://colab.research.google.com/github/pytorch/audio/blob/gh-pages/main/_downloads" + notebookDownloadPath;

	      $(".pytorch-call-to-action-links a[data-response='Run in Google Colab']").attr("href", colabLink);
	      $(".pytorch-call-to-action-links a[data-response='View on Github']").attr("href", githubLink);
	  }

          var overwrite = function(_) {
              if ($(this).length > 0) {
                  $(this)[0].href = "https://github.com/pytorch/audio"
              }
          }
          // PC
          $(".main-menu a:contains('GitHub')").each(overwrite);
          // Mobile
          $(".main-menu a:contains('Github')").each(overwrite);
      });

      
      
       $(window).ready(function() {
           var original = window.sideMenus.bind;
           var startup = true;
           window.sideMenus.bind = function() {
               original();
               if (startup) {
                   $("#pytorch-right-menu a.reference.internal").each(function(i) {
                       if (this.classList.contains("not-expanded")) {
                           this.nextElementSibling.style.display = "block";
                           this.classList.remove("not-expanded");
                           this.classList.add("expanded");
                       }
                   });
                   startup = false;
               }
           };
       });
      
    </script>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>