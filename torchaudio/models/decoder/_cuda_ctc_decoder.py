from __future__ import annotations

import itertools as it

import warnings
from abc import abstractmethod
from collections import namedtuple
from typing import Dict, List, NamedTuple, Optional, Tuple, Union
import math

import torch
import torchaudio
from torchaudio.utils import download_asset

torchaudio._extension._load_lib("libctc_prefix_decoder")
import torchaudio.lib.pybind11_prefixctc as cuctc


__all__ = [
    "CUCTCHypothesis",
    "CUCTCDecoder",
    "cuda_ctc_decoder"
]

def _get_vocab_list(vocab_file):
    vocab = []
    with open(vocab_file, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip().split()
            vocab.append(line[0])
    return vocab


class CUCTCHypothesis(NamedTuple):
    r"""Represents hypothesis generated by CUCTC beam search decoder :class:`CUCTCDecoder`."""
    tokens: List[int]
    """Predicted sequence of token IDs. Shape `(L, )`, where `L` is the length of the output sequence"""

    words: List[str]
    """List of predicted tokens. Algin with modeling unit. 
    """

    score: float
    """Score corresponding to hypothesis"""

class CUCTCDecoder:
    """CUDA CTC beam search decoder.

    .. devices:: GPU

    Note:
        To build the decoder, please use the factory function :func:`cuda_ctc_decoder`.
    """
    def __init__(self,
                 vocab_list: List[str],
                 blank_id: int = 0,
                 beam_size: int = 10,
                 nbest: int = 1,
                 blank_skip_threshold: float = math.log(0.95),
                 cuda_stream: torch.cuda.streams.Stream = None):
        """
        Args:
            blank_id (int): token id corresopnding to blank (Default: 0)
            vocab_list (List[str]): list of vocabulary tokens
            beam_size (int, optional): max number of hypos to hold after each decode step (Default: 10)
            nbest (int): number of best decodings to return
            blank_skip_threshold (float): skip frames if log_prob(blank) > blank_skip_threshold, to speed up decoding
            cuda_stream (torch.cuda.streams.Stream): using assigned cuda stream (Default: using default stream)

        """
        if cuda_stream:
            assert (isinstance(cuda_stream, torch.cuda.streams.Stream))
        cuda_stream_ = cuda_stream.cuda_stream if cuda_stream else torch.cuda.current_stream().cuda_stream
        self.internal_data = cuctc.prefixCTC_alloc(cuda_stream_)
        self.memory = torch.empty(0, dtype=torch.int8, device=torch.device('cuda'))
        self.blank_id = 0 # TODO: allow to customize blank_id
        self.vocab_list = vocab_list
        self.space_id = 0
        self.nbest = nbest
        self.blank_skip_threshold = blank_skip_threshold
        self.beam_size = beam_size

    def __del__(self):
        cuctc.prefixCTC_free(self.internal_data)

    def __call__(self, log_prob: torch.Tensor, encoder_out_lens: torch.Tensor):
        """
        Args:
            log_prob (torch.FloatTensor): GPU tensor of shape `(batch, frame, num_tokens)` storing sequences of
                probability distribution over labels; log_softmax(output of acoustic model).
            lengths (dtype torch.int32): GPU tensor of shape `(batch, )` storing the valid length of
                in time axis of the output Tensor in each batch.

        Returns:
            List[List[CUCTCHypothesis]]:
                List of sorted best hypotheses for each audio sequence in the batch.
        """
        assert(encoder_out_lens.dtype==torch.int32), "encoder_out_lens must be torch.int32"
        assert(log_prob.dtype == torch.float32), "log_prob must be torch.float32"
        assert log_prob.is_cuda and encoder_out_lens.is_cuda, "inputs must be cuda tensors"
        required_size, score_hyps = cuctc.ctc_beam_search_decoder_batch_gpu_v2(self.internal_data, self.memory.data_ptr(),
                                                       self.memory.size(0), log_prob.data_ptr(),
                                                       encoder_out_lens.data_ptr(), log_prob.size(),
                                                       log_prob.stride(), self.beam_size, self.blank_id,
                                                       self.space_id, self.blank_skip_threshold)
        if (required_size > 0):
            self.memory = torch.empty(
                required_size, dtype=torch.int8, device=log_prob.device).contiguous()
            _, score_hyps = cuctc.ctc_beam_search_decoder_batch_gpu_v2(self.internal_data, self.memory.data_ptr(),
                                                                       self.memory.size(0), log_prob.data_ptr(),
                                                                       encoder_out_lens.data_ptr(), log_prob.size(),
                                                                       log_prob.stride(), self.beam_size, self.blank_id,
                                                                       self.space_id, self.blank_skip_threshold)
        batch_size = len(score_hyps)
        hypos = []
        for i in range(batch_size):
            hypos.append(
                [
                    CUCTCHypothesis(
                        tokens=score_hyps[i][j][1],
                        words=[self.vocab_list[word_id] for word_id in score_hyps[i][j][1]],
                        score=score_hyps[i][j][0]
                    )
                    for j in range(self.nbest)
                ]
            )
        return hypos

def cuda_ctc_decoder(
    tokens: Union[str, List[str]],
    nbest: int = 1,
    beam_size: int = 10,
    blank_skip_threshold: float = math.log(0.95)
) -> CUCTCDecoder:
    """Builds an instance of :class:`CUCTCDecoder`.

    Args:
        tokens (str or List[str]): file or list containing valid tokens. If using a file, the expected
            format is for tokens mapping to the same index to be on the same line
        beam_size (int, optional): max number of hypos to hold after each decode step (Default: 10)
        nbest (int): number of best decodings to return
        blank_id (int): token id corresopnding to blank symbol
        blank_skip_threshold (float): skip frames if log_prob(blank) > blank_skip_threshold, to speed up decoding
        
    Returns:
        CUCTCDecoder: decoder

    Example
        >>> decoder = cuda_ctc_decoder(
        >>>     vocab_file="tokens.txt",
        >>>     blank_skip_threshold=math.log(0.95),
        >>> )
        >>> results = decoder(log_probs, encoder_out_lens) # List of shape (B, nbest) of Hypotheses
    """
    if type(tokens) == str:
        tokens = _get_vocab_list(tokens)

    return CUCTCDecoder(
        vocab_list=tokens,
        beam_size=beam_size,
        nbest=nbest,
        blank_skip_threshold=blank_skip_threshold
    )